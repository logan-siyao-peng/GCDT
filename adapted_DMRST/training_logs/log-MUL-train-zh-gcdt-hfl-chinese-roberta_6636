/var/spool/slurmd/job06636/slurm_script: line 11: activate: No such file or directory
No Modulefiles Currently Loaded.
Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
args.use_org_Parseval: True
language embedding name:  hfl/chinese-roberta-wwm-ext
Language embedding loaded from pretrained:  hfl/chinese-roberta-wwm-ext
Checking Data...
 英 语 中 动 态 的 象 似 性 分 析 1 . 导 论 从 广 义 的 角 度 来 看 ， 英 语 中 主 要 分 为 三 个 [UNK] 态 [UNK] ： 主 动 态 ， 中 动 态 和 被 动 态 。 英 语 中 动 态 是 一 种 特 殊 的 语 态 形 式 ， 因 为 它 缺 少 施 事 [ 1 ] 。 从 语 义 的 角 度 来 看 ， 英 语 中 动 态 具 有 如 下 特 点 ： 1 ) 非 事 件 性 ； 2 ) 泛 指 性 ； 3 ) 施 动 性 ； 4 ) 情 态 概 念 [ 2 ] 。 在 主 动 态 的 象 似 性 研 究 中 ， 施 事 的 动 作 产 生 无 论 如 何 先 于 过 程 对 受 事 的 影 响 ， 也 就 是 因 ( 施 事 ) 先 于 果 ( 过 程 对 受 事 的 影 响 ) ， 因 此 ， 主 动 态 是 最 符 合 象 似 性 原 则 的 表 达 。 在 被 动 态 结 构 中 ， 施 事 先 于 受 事 ， 明 显 违 背 了 象 似 性 原 则 。 那 么 ， 就 中 动 态 而 言 ， 它 的 语 法 结 构 是 主 动 态 的 ， 但 是 各 参 与 成 分 之 间 的 关 系 是 被 动 态 的 ， 我 们 如 何 从 象 似 性 角 度 来 分 析 它 呢 ？ 本 文 主 要 探 讨 了 英 语 中 动 态 的 象 似 性 特 点 。 本 文 提 出 的 问 题 如 下 ： ① 英 语 中 动 态 是 如 何 遵 守 或 违 背 象 似 性 原 则 的 ？ ② 英 语 中 动 态 违 背 象 似 性 原 则 的 理 据 为 何 ？ 2 . 象 似 性 原 则 2 . 1 . 顺 序 象 似 性 顺 序 象 似 性 可 以 定 义 为 ： 思 维 的 顺 序 与 语 言 单 位 排 列 的 顺 序 象 似 [ 3 ] 。 green ##berg 也 表 示 ： [UNK] 语 言 成 分 的 顺 序 对 应 与 物 理 现 实 经 验 顺 序 或 知 识 顺 序 [UNK] the order of el ##ement ##s in language pa ##ral ##le ##ls that in ph ##ys ##ical ex ##per ##ience or the order of know ##led ##ge [ 4 ] 。 文 旭 ( 2009 ) 将 这 一 原 则 进 一 步 分 为 两 个 原 则 [ 5 ] ： 1 ) 线 性 序 列 时 间 原 则 ： 连 贯 话 语 中 分 句 的 顺 序 对 应 于 其 所 描 写 的 事 件 发 生 的 时 间 顺 序 。 比 如 [UNK] i cam ##e , i sa ##w , i con ##que ##red . [UNK] 又 比 如 ： max hit harry and harry hit max 表 示 max hit harry 在 先 ， harry hit max 在 后 。 而 max and harry hit ea ##ch other 则 没 有 体 现 出 这 种 时 间 先 后 的 概 念 。 2 ) 线 性 序 列 信 息 原 则 。 该 原 则 主 要 是 与 信 息 的 分 配 相 联 系 。 谈 到 信 息 分 配 ， 我 们 主 要 采 用 的 是 hall ##ida ##y 系 统 功 能 语 言 学 关 于 信 息 分 布 的 观 点 。 hall ##ida ##y & matt ##hi ##ess ##en [ 1 ] 认 为 主 位 ( the ##me ) 是 句 中 信 息 的 起 点 ， 是 整 个 小 句 所 关 注 和 讨 论 的 ， 也 是 小 句 得 以 展 开 的 背 景 。 小 句 中 发 展 主 位 的 部 分 被 称 之 为 述 位 ( r ##he ##me ) 。 通 常 在 陈 述 句 中 非 标 记 性 主 位 ( u ##nm ##ark ##ed the ##me ) 与 主 语 重 合 ， 主 语 以 外 的 任 何 成 分 都 是 标 记 性 主 位 ( mark ##ed the ##me ) [ 1 ] 。 就 信 息 结 构 在 语 言 结 构 中 的 体 现 而 言 ， 非 标 记 式 匹 配 是 ： 与 主 语 重 合 的 非 标 记 性 主 位 传 达 的 是 旧 信 息 ， 而 述 位 传 达 的 是 新 信 息 。 在 语 言 使 用 过 程 中 ， 我 们 会 调 整 主 位 的 实 现 成 分 重 新 分 配 信 息 量 ， 这 样 ， 标 记 性 或 非 象 似 性 表 达 就 产 生 了 。 线 性 序 列 信 息 原 则 表 示 最 熟 悉 的 已 知 背 景 信 息 先 出 现 ， 最 不 熟 悉 的 新 信 息 后 出 现 。 hall ##ida ##y & matt ##hi ##ess ##en [ 1 ] 认 为 主 位 表 达 旧 信 息 ， 述 位 表 达 新 信 息 是 非 标 记 性 信 息 匹 配 结 构 ； 但 是 在 语 言 使 用 中 ， 我 们 可 以 利 用 主 谓 结 构 和 信 息 结 构 [ 的 错 配 ( mi ##sm ##at ##ch ) ] 来 达 到 意 想 不 到 的 修 辞 效 果 。 hall ##ida ##y 也 曾 明 确 表 示 了 象 似 性 的 概 念 ， 他 说 ： 在 语 言 表 达 中 存 在 以 下 规 律 ， 即 信 息 流 沿 着 从 旧 信 息 ( 主 位 ) 流 向 新 信 息 ( 述 位 ) 的 方 向 移 动 ， 这 种 遵 循 时 间 顺 序 的 移 动 象 似 性 地 始 解 了 信 息 流 的 传 播 方 向 ( there is a mo ##ve ##ment from a gi ##ven the ##me ( back ##ground ) to r ##he ##ma ##tic new ( for ##eg ##ro ##und ) ; this mo ##ve ##ment in time con ##st ##ru ##es icon ##ical ##ly the f ##low of information ) [ 6 ] 。 2 . 2 . 距 离 象 似 性 根 据 文 旭 [ 5 ] ， 距 离 象 似 性 定 义 如 下 ： 概 念 间 的 距 离 对 应 于 语 言 成 分 之 间 的 距 离 。 ha ##ima ##n [ 7 ] 认 为 两 个 观 点 在 概 念 的 接 近 必 须 满 足 以 下 四 个 条 件 ： 1 ) 彼 此 享 有 语 义 特 点 或 部 分 ； 2 ) 相 互 影 响 ； 3 ) 在 现 实 中 不 可 分 离 ； 4 ) 不 管 在 现 实 中 可 不 可 以 分 离 ， 均 视 为 一 个 整 体 。 2 . 3 . 数 量 象 似 性 根 据 王 寅 [ 8 ] 数 量 象 似 性 的 定 义 为 ： 语 言 单 位 的 数 量 与 所 表 示 的 概 念 的 量 和 复 杂 程 度 成 正 比 象 似 ， 与 可 预 测 度 成 反 比 。 数 量 象 似 性 的 认 知 基 础 是 ： 语 言 单 位 数 量 一 多 ， 就 会 更 多 地 引 起 人 们 的 注 意 力 ， 心 智 加 工 也 就 更 复 杂 ， 传 递 的 信 息 量 自 然 也 会 更 多 [ 9 ] 。 gi ##vo ##n [ 10 ] 指 出 ， 信 息 处 理 过 程 中 投 入 更 多 的 心 智 努 力 ( men ##tal ef ##fo ##rt ) 需 要 更 多 的 语 言 编 码 材 料 来 表 达 。 语 言 的 每 一 个 单 位 得 以 被 应 用 都 有 它 能 被 使 用 的 价 值 ， 这 个 价 值 就 是 传 递 相 应 的 意 义 ， 因 此 ， 语 言 单 位 越 多 ， 必 定 要 传 递 更 多 的 概 念 。 2 . 4 . 对 称 象 似 性 根 据 ha ##ima ##n [ 7 ] 对 称 象 似 性 指 的 是 语 言 形 式 的 对 称 或 非 对 称 形 式 表 达 了 语 言 形 式 各 部 分 代 表 的 概 念 之 间 存 在 的 对 称 关 系 或 不 对 称 关 系 ( ( a ) s ##ym ##me ##try of form will re ##fl ##ect con ##cept ##ual ( a ) s ##ym ##me ##try ) 。 比 如 sim ##il ##ari ##ty 表 达 的 是 绝 对 对 称 性 概 念 。 harry is sim ##il ##ar to max 与 max is sim ##il ##ar to harry 是 完 全 对 称 的 。 like 表 示 的 不 是 绝 对 对 称 概 念 ， 比 如 max like ##s harry 并 不 与 harry like ##s max 对 称 。 ha ##ima ##n 通 过 多 语 言 对 比 ， 发 现 and 也 可 以 被 用 作 因 果 丛 句 和 条 件 丛 句 。 比 如 ： sam ##my [UNK] s ma ##d and i [UNK] m gl ##ad 和 he come ##s , i will stay 。 在 这 两 句 中 ， su ##mmy [UNK] ma ##d 和 he come ##s 被 看 作 是 表 原 因 的 小 句 。 ha ##ima ##n [ 7 ] 认 为 这 是 一 种 概 念 对 称 的 体 现 ， 因 为 根 据 时 间 的 线 性 特 点 ， 最 先 发 生 的 可 以 看 作 是 背 景 ， 原 因 ， 条 件 。
... ...
That's great! No error found!
All train sample number: 40
Model save path depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed111/
Finetune from path None
Total trainable parameter number is:  93938722
self.use_org_Parseval:  True
whole iter list [4, 27, 28, 3, 35, 0, 2, 16, 23, 19] max:min 39 0
epoch:1, iteration:0
4.3490142822265625 6.827268123626709 1.8669968843460083
epoch:1, iteration:5
2.653219699859619 4.752248764038086 1.7097572088241577
lambda: 0.9553349622822912 1.017874487898665 1.026790549819044
epoch:1, iteration:10
2.531620502471924 4.552158832550049 1.5273295640945435
lambda: 0.9210462901481155 1.0782663427244412 1.0006873671274434
epoch:1, iteration:15
3.651482105255127 4.223515033721924 1.3904471397399902
lambda: 0.8730567193352976 1.1038710130998775 1.0230722675648247
epoch:1, iteration:20
2.1305551528930664 3.469900369644165 1.4128129482269287
lambda: 0.9150572017243251 1.123476932096461 0.9614658661792135
epoch:1, iteration:25
2.0752193927764893 3.5404462814331055 1.211051106452942
lambda: 1.0051140143642536 0.9794237901931785 1.0154621954425678
epoch:1, iteration:30
2.3678038120269775 3.033060073852539 1.2267167568206787
lambda: 1.0991384262764055 0.921943202989838 0.9789183707337566
epoch:1, iteration:35
2.509915351867676 3.6052207946777344 1.1707677841186523
lambda: 1.0522590261894054 0.9317647631383817 1.0159762106722132
Epoch Dev:	1
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.5849	0.3412	0.2999
Epoch Test:	1
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.5818	0.3390	0.2869
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed111/Epoch_1.torchsave
whole iter list [3, 38, 35, 33, 14, 2, 25, 32, 7, 20] max:min 39 0
epoch:2, iteration:0
2.4653100967407227 2.688577651977539 1.247171401977539
lambda: 1.1614610269118306 0.9156450723967366 0.9228939006914325
epoch:2, iteration:5
2.1753711700439453 3.089982271194458 1.119591236114502
lambda: 1.1093582403369726 0.9137060359992186 0.9769357236638083
epoch:2, iteration:10
1.6747974157333374 2.8962996006011963 1.0988657474517822
lambda: 0.9628978684783067 1.006635637897727 1.0304664936239663
epoch:2, iteration:15
1.9624093770980835 2.915052890777588 1.1081047058105469
lambda: 0.8589293027751533 1.097258565731894 1.0438121314929523
epoch:2, iteration:20
1.3570551872253418 2.706754446029663 1.034497618675232
lambda: 0.9477599263526819 0.9472330189837407 1.1050070546635775
epoch:2, iteration:25
1.5312153100967407 1.9229040145874023 0.9407010078430176
lambda: 1.0163183931346653 0.9887225145480261 0.9949590923173088
epoch:2, iteration:30
2.0301077365875244 3.62781023979187 0.9379395246505737
lambda: 1.09959087346668 0.9675346206537322 0.9328745058795882
epoch:2, iteration:35
1.7127174139022827 2.7952404022216797 0.8749567270278931
lambda: 1.0119572844872546 1.0258432046412573 0.962199510871488
Epoch Dev:	2
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.6508	0.3940	0.3518
Epoch Test:	2
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.6655	0.4110	0.3597
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed111/Epoch_2.torchsave
whole iter list [33, 21, 36, 38, 20, 10, 25, 26, 15, 9] max:min 39 0
epoch:3, iteration:0
1.773654818534851 2.774528980255127 0.9572411179542542
lambda: 0.9553220798999361 0.9812964787745091 1.063381441325555
epoch:3, iteration:5
1.8079886436462402 2.7210464477539062 0.9333961009979248
lambda: 0.9481359532944472 1.007302951411655 1.0445610952938977
epoch:3, iteration:10
1.4167932271957397 2.2577764987945557 0.8109776973724365
lambda: 1.1311428131419126 1.0368319331626081 0.8320252536954791
epoch:3, iteration:15
1.5250215530395508 2.4921205043792725 0.899258017539978
lambda: 0.949280825612364 1.0210444422236449 1.0296747321639907
epoch:3, iteration:20
1.5885733366012573 2.0202269554138184 0.7457551956176758
lambda: 1.0142892026313537 0.9702218621562574 1.0154889352123888
epoch:3, iteration:25
2.0669615268707275 2.3528025150299072 0.9754837155342102
lambda: 0.9523126963794747 0.9508724424448869 1.0968148611756383
epoch:3, iteration:30
1.0371171236038208 2.2425003051757812 0.8957822918891907
lambda: 0.7701141406132989 1.4005425240979827 0.8293433352887184
epoch:3, iteration:35
1.481115460395813 2.0812830924987793 0.7893229722976685
lambda: 0.9606013016802779 0.9662998127629893 1.0730988855567327
Epoch Dev:	3
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.6631	0.4336	0.3887
Epoch Test:	3
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.6853	0.4460	0.3939
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed111/Epoch_3.torchsave
whole iter list [6, 7, 9, 2, 24, 34, 12, 22, 39, 29] max:min 39 0
epoch:4, iteration:0
1.5229520797729492 2.187227249145508 0.8400300145149231
lambda: 1.241063462873817 0.8953511517671001 0.8635853853590824
epoch:4, iteration:5
1.3332676887512207 2.407067060470581 0.7175694108009338
lambda: 0.9017159040850077 1.0271841941847972 1.071099901730195
epoch:4, iteration:10
1.2714027166366577 2.5670955181121826 0.8016278147697449
lambda: 0.9263559495466329 1.0182071567567663 1.0554368936966008
epoch:4, iteration:15
1.6788647174835205 2.323601484298706 0.7876797318458557
lambda: 1.027818229341333 0.9846445346688272 0.9875372359898399
epoch:4, iteration:20
1.2848790884017944 1.98820960521698 0.6625988483428955
lambda: 0.9968137203337675 0.9458445045365156 1.0573417751297174
epoch:4, iteration:25
1.622312307357788 2.281343936920166 0.8583930730819702
lambda: 1.0559956325468152 0.8466628537322599 1.0973415137209253
epoch:4, iteration:30
1.5070619583129883 1.6504087448120117 0.7230836153030396
lambda: 0.9979128679189745 0.95997148585583 1.0421156462251955
epoch:4, iteration:35
1.2034982442855835 1.7836459875106812 0.7134349942207336
lambda: 1.1081692771613045 0.9368094057845276 0.9550213170541679
Epoch Dev:	4
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7221	0.4802	0.4406
Epoch Test:	4
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7023	0.4640	0.4092
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed111/Epoch_4.torchsave
whole iter list [5, 0, 1, 35, 10, 2, 31, 29, 9, 17] max:min 39 0
epoch:5, iteration:0
1.3015823364257812 1.9730597734451294 0.6751912832260132
lambda: 1.1708002295637552 0.9090609344623762 0.9201388359738688
epoch:5, iteration:5
0.9938872456550598 1.6028413772583008 0.6954807043075562
lambda: 1.051390726702389 1.0156775259098207 0.9329317473877905
epoch:5, iteration:10
0.7668362855911255 1.603091835975647 0.6628286838531494
lambda: 0.8729128969828591 1.0610819011418042 1.0660052018753365
epoch:5, iteration:15
1.0876288414001465 1.8559613227844238 0.5837262868881226
lambda: 0.9542548629989528 1.0048289201612024 1.040916216839845
epoch:5, iteration:20
1.3261371850967407 1.878233551979065 0.7431052327156067
lambda: 0.809067159768167 1.3138762052067796 0.8770566350250535
epoch:5, iteration:25
1.2904561758041382 1.565510630607605 0.5962209701538086
lambda: 1.0070658799039638 1.1179391350541341 0.8749949850419021
epoch:5, iteration:30
1.033211350440979 1.5983738899230957 0.5731228590011597
lambda: 1.0153342260279892 1.000129905207282 0.9845358687647286
epoch:5, iteration:35
1.1761870384216309 1.5577532052993774 0.605993390083313
lambda: 1.073406595817102 1.0920712438824052 0.8345221603004929
Epoch Dev:	5
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7265	0.5048	0.4600
Epoch Test:	5
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7320	0.4910	0.4424
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed111/Epoch_5.torchsave
whole iter list [9, 32, 17, 5, 1, 30, 10, 18, 6, 3] max:min 39 0
epoch:6, iteration:0
1.8944759368896484 1.2351090908050537 0.5437233448028564
lambda: 1.0571603555316562 0.820801191563536 1.122038452904808
epoch:6, iteration:5
0.9147388935089111 1.2656611204147339 0.6306957006454468
lambda: 0.9645831382862424 1.0599321498523502 0.9754847118614074
epoch:6, iteration:10
0.8511889576911926 1.6484653949737549 0.6462637782096863
lambda: 0.9194257400178975 0.9666051953382573 1.1139690646438452
epoch:6, iteration:15
1.2115213871002197 1.3028615713119507 0.5916217565536499
lambda: 0.928243706835907 1.0416633875189572 1.0300929056451358
epoch:6, iteration:20
1.1274049282073975 0.8935919404029846 0.6925573348999023
lambda: 0.9689924277307845 0.943032602745538 1.0879749695236776
epoch:6, iteration:25
1.1260215044021606 1.6603139638900757 0.5304846167564392
lambda: 1.0457148002554382 1.1270015327944116 0.8272836669501504
epoch:6, iteration:30
0.9955501556396484 1.8398933410644531 0.6256863474845886
lambda: 0.9422286159478277 1.1614445073371245 0.896326876715048
epoch:6, iteration:35
0.7303784489631653 1.4670886993408203 0.5346258878707886
lambda: 0.9212828348293007 1.0076473738851934 1.0710697912855056
Epoch Dev:	6
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7467	0.5145	0.4732
Epoch Test:	6
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7473	0.5135	0.4604
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed111/Epoch_6.torchsave
whole iter list [38, 13, 15, 30, 20, 17, 11, 35, 25, 4] max:min 39 0
epoch:7, iteration:0
0.8910269737243652 1.4221264123916626 0.5240435004234314
lambda: 1.1216410875606575 0.9224585882469912 0.9559003241923515
epoch:7, iteration:5
0.9862047433853149 1.3291079998016357 0.6179308891296387
lambda: 1.0474289943364001 1.021229032446216 0.9313419732173839
epoch:7, iteration:10
1.0054564476013184 1.1162558794021606 0.6603775024414062
lambda: 0.8859489146416515 1.106958876595838 1.0070922087625103
epoch:7, iteration:15
1.123745083808899 1.555155634880066 0.6773000359535217
lambda: 1.1285297384566217 1.0638197828595486 0.8076504786838296
epoch:7, iteration:20
1.1513885259628296 1.5917340517044067 0.6402615308761597
lambda: 0.9728191571200008 1.045648600515004 0.9815322423649954
epoch:7, iteration:25
0.6606689691543579 1.5142031908035278 0.5901875495910645
lambda: 0.5726791349109652 1.5895648385167904 0.8377560265722441
epoch:7, iteration:30
1.112313151359558 1.1910383701324463 0.5238763689994812
lambda: 0.9314259358554018 1.200081756809721 0.868492307334877
epoch:7, iteration:35
1.2803419828414917 1.757080316543579 0.5461368560791016
lambda: 1.0470258528339476 0.9605951465544001 0.9923790006116525
Epoch Dev:	7
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7520	0.5383	0.4960
Epoch Test:	7
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7446	0.5306	0.4982
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed111/Epoch_7.torchsave
whole iter list [16, 37, 27, 7, 8, 0, 38, 22, 21, 29] max:min 39 0
epoch:8, iteration:0
0.6352695226669312 1.4133585691452026 0.6008791923522949
lambda: 0.9900877145972881 1.0905184690709147 0.9193938163317973
epoch:8, iteration:5
0.66342693567276 1.255933403968811 0.6015575528144836
lambda: 0.8936754216549045 1.0500158820535332 1.0563086962915622
epoch:8, iteration:10
0.9173753261566162 1.4729613065719604 0.6481570601463318
lambda: 1.1028760136001612 0.8304585180037751 1.0666654683960635
epoch:8, iteration:15
0.7841498851776123 1.1625062227249146 0.5911911725997925
lambda: 1.087282247492378 0.886815811248385 1.025901941259237
epoch:8, iteration:20
1.3096802234649658 1.0028891563415527 0.477561354637146
lambda: 1.0760303169408614 0.8327552577477895 1.0912144253113492
epoch:8, iteration:25
0.96980220079422 0.4370788633823395 0.47020024061203003
lambda: 1.0012645109932568 0.9591244917416681 1.039610997265075
epoch:8, iteration:30
0.8870795965194702 0.8834804892539978 0.592960000038147
lambda: 1.0110934261354303 0.9651674959081367 1.023739077956433
epoch:8, iteration:35
0.8042867183685303 1.356782078742981 0.5058161616325378
lambda: 0.9117071931055918 1.1246548008204058 0.9636380060740023
Epoch Dev:	8
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7458	0.5479	0.4996
Epoch Test:	8
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7482	0.5207	0.4838
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed111/Epoch_8.torchsave
whole iter list [14, 10, 38, 12, 5, 15, 33, 6, 31, 39] max:min 39 0
epoch:9, iteration:0
0.9279781579971313 1.0728191137313843 0.4681973457336426
lambda: 1.0214920168232189 1.173143758958021 0.8053642242187604
epoch:9, iteration:5
0.6895977854728699 0.7352426648139954 0.5414959192276001
lambda: 0.872463728270478 1.2282123746998628 0.8993238970296595
epoch:9, iteration:10
0.7235199213027954 1.0542707443237305 0.5030384659767151
lambda: 1.0978390274960441 0.8232587766349897 1.0789021958689655
epoch:9, iteration:15
0.8963463306427002 1.5150355100631714 0.43109259009361267
lambda: 1.0143935145117995 0.9520039670581538 1.0336025184300466
epoch:9, iteration:20
0.5306510329246521 1.361672043800354 0.4151768982410431
lambda: 1.1501581808723844 0.9270398855499925 0.9228019335776234
epoch:9, iteration:25
0.7387730479240417 0.8151244521141052 0.534146249294281
lambda: 1.1189904475014962 1.0845224449383608 0.7964871075601431
epoch:9, iteration:30
0.68611741065979 1.2845165729522705 0.4328081011772156
lambda: 0.8282826867048606 1.3134300420805987 0.8582872712145411
epoch:9, iteration:35
0.6930553913116455 1.1985267400741577 0.53236985206604
lambda: 1.0493418572762532 0.9457066245415938 1.004951518182153
Epoch Dev:	9
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7564	0.5576	0.5119
Epoch Test:	9
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7545	0.5288	0.4910
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed111/Epoch_9.torchsave
whole iter list [13, 16, 34, 28, 23, 27, 7, 32, 20, 25] max:min 39 0
epoch:10, iteration:0
0.6487681269645691 1.1494077444076538 0.4587435722351074
lambda: 0.9183800414648559 0.9334920518871119 1.148127906648032
epoch:10, iteration:5
0.5509308576583862 1.2147116661071777 0.45034435391426086
lambda: 0.688807720111777 1.4954737577043349 0.8157185221838884
epoch:10, iteration:10
0.7273194193840027 1.1257637739181519 0.5035767555236816
lambda: 1.2205901765582579 0.8445149752950301 0.934894848146712
epoch:10, iteration:15
0.5222266316413879 1.120421290397644 0.40158188343048096
lambda: 1.1976485957998935 0.8270621087396819 0.9752892954604244
epoch:10, iteration:20
0.6550208926200867 0.9185349345207214 0.468191534280777
lambda: 1.06850506293237 0.9031381806261369 1.0283567564414928
epoch:10, iteration:25
0.5301684737205505 1.0524872541427612 0.537704348564148
lambda: 0.903229885748749 0.9686545643888872 1.128115549862364
epoch:10, iteration:30
0.7562756538391113 1.2829238176345825 0.41240790486335754
lambda: 0.9524265802772991 1.022709205539124 1.0248642141835769
epoch:10, iteration:35
0.658698558807373 1.125346064567566 0.447998046875
lambda: 0.9817121094983625 1.0274359188138018 0.9908519716878356
Epoch Dev:	10
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7529	0.5365	0.4996
Epoch Test:	10
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7608	0.5351	0.5036
whole iter list [0, 3, 13, 27, 35, 37, 39, 15, 22, 12] max:min 39 0
epoch:11, iteration:0
0.4794847071170807 1.1541552543640137 0.48017507791519165
lambda: 0.8839953379737525 0.9460112072188698 1.1699934548073774
epoch:11, iteration:5
0.7018919587135315 1.2528594732284546 0.44140779972076416
lambda: 0.9151972824481547 1.023951818745734 1.0608508988061112
epoch:11, iteration:10
0.697868824005127 0.9841181635856628 0.4454989731311798
lambda: 0.996853854290302 0.8609087168532035 1.1422374288564947
epoch:11, iteration:15
0.7555217146873474 1.441646933555603 0.4862346649169922
lambda: 0.9303012324482134 1.024557683670428 1.0451410838813586
epoch:11, iteration:20
0.49200353026390076 0.5600774884223938 0.4747765064239502
lambda: 1.0424851777786863 1.1034207496667239 0.8540940725545896
epoch:11, iteration:25
0.7205223441123962 1.4616918563842773 0.38299185037612915
lambda: 0.856099457689144 1.3154155655026405 0.8284849768082154
epoch:11, iteration:30
0.968052327632904 1.2571909427642822 0.5766282081604004
lambda: 0.9905669060066612 0.9503926054450105 1.0590404885483282
epoch:11, iteration:35
0.6045422554016113 1.1871505975723267 0.40006762742996216
lambda: 1.412827502968804 0.7187431210503131 0.8684293759808827
Epoch Dev:	11
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7555	0.5690	0.5268
Epoch Test:	11
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7716	0.5459	0.5090
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed111/Epoch_11.torchsave
whole iter list [3, 10, 14, 12, 7, 32, 19, 34, 13, 1] max:min 39 0
epoch:12, iteration:0
0.5861307978630066 0.8996180295944214 0.4661789536476135
lambda: 0.49879128123808075 1.9871475503593317 0.5140611684025874
epoch:12, iteration:5
0.6964717507362366 0.7940346002578735 0.35371601581573486
lambda: 0.9793211538837246 1.2153225613185954 0.8053562847976802
epoch:12, iteration:10
0.5027704834938049 1.1294565200805664 0.37259918451309204
lambda: 0.8666825130706018 1.0740223941427265 1.0592950927866716
epoch:12, iteration:15
0.6498597264289856 1.0747898817062378 0.44313591718673706
lambda: 1.1107766505271435 0.8688603773560831 1.0203629721167735
epoch:12, iteration:20
0.6609677076339722 0.9239760637283325 0.4689193069934845
lambda: 1.012151572808797 0.9620940590445911 1.0257543681466117
epoch:12, iteration:25
0.706896960735321 1.0578856468200684 0.41660749912261963
lambda: 1.026703619121007 1.0008058020132027 0.9724905788657904
epoch:12, iteration:30
0.7383390069007874 0.4567194879055023 0.4530215263366699
lambda: 0.8554590998628395 1.3912990542483112 0.7532418458888493
epoch:12, iteration:35
0.8325835466384888 1.3532121181488037 0.5032021999359131
lambda: 1.13656367114884 0.8574136422733802 1.0060226865777795
Epoch Dev:	12
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7625	0.5761	0.5207
Epoch Test:	12
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7590	0.5414	0.5045
whole iter list [31, 37, 16, 18, 3, 17, 14, 21, 10, 13] max:min 39 0
epoch:13, iteration:0
0.6729449033737183 1.303309440612793 0.39762234687805176
lambda: 1.3682136971478767 0.6968346168736008 0.9349516859785224
epoch:13, iteration:5
0.5494288206100464 0.9502153396606445 0.4616527855396271
lambda: 0.9683947318468817 0.913018368886279 1.1185868992668393
epoch:13, iteration:10
0.8191385865211487 1.2530573606491089 0.5372471809387207
lambda: 0.9431682420751112 0.9837614813289959 1.0730702765958928
epoch:13, iteration:15
0.46871867775917053 0.9189730882644653 0.38142621517181396
lambda: 1.0155189083133023 1.424072461048677 0.5604086306380208
epoch:13, iteration:20
1.12417471408844 0.7735681533813477 0.39425361156463623
lambda: 0.9921740615486866 1.0155152365034739 0.9923107019478397
epoch:13, iteration:25
0.5228311419487 0.8118268251419067 0.31792914867401123
lambda: 0.946169177739638 0.9806660762797718 1.0731647459805902
epoch:13, iteration:30
0.6111170053482056 0.5807755589485168 0.4504140019416809
lambda: 1.021408925185671 1.093208692335023 0.8853823824793057
epoch:13, iteration:35
0.33048683404922485 0.8283240795135498 0.4056195914745331
lambda: 0.8882552965734154 1.1158156336295586 0.9959290697970259
Epoch Dev:	13
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7573	0.5594	0.5172
Epoch Test:	13
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7581	0.5405	0.5045
whole iter list [38, 26, 9, 0, 2, 10, 8, 28, 23, 7] max:min 39 0
epoch:14, iteration:0
0.5647611021995544 0.9621027708053589 0.35320475697517395
lambda: 0.9017593740033875 1.090004548454322 1.0082360775422903
epoch:14, iteration:5
0.9147979021072388 1.2132041454315186 0.4286436438560486
lambda: 1.2191023379699966 0.8930842848171672 0.8878133772128362
epoch:14, iteration:10
0.5973097681999207 1.0965276956558228 0.3668389320373535
lambda: 1.089334714465491 1.0450551702350455 0.8656101152994641
epoch:14, iteration:15
0.5679989457130432 0.9017237424850464 0.42593953013420105
lambda: 0.9457134750959717 1.2183041610761582 0.83598236382787
epoch:14, iteration:20
0.487174928188324 1.1077643632888794 0.37410968542099
lambda: 1.299534793930849 0.7460852376529621 0.9543799684161891
epoch:14, iteration:25
0.4275455176830292 0.6586918830871582 0.40285730361938477
lambda: 0.8911000623859919 0.9480712039001556 1.1608287337138525
epoch:14, iteration:30
0.8582760095596313 0.9045748114585876 0.4192691445350647
lambda: 1.0469615675593351 1.0486386140732806 0.9043998183673841
epoch:14, iteration:35
0.8457148671150208 1.6077789068222046 0.4515702724456787
lambda: 1.0209139189536935 1.1022331762115807 0.8768529048347257
Epoch Dev:	14
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7581	0.5629	0.5154
Epoch Test:	14
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7653	0.5531	0.5198
whole iter list [29, 32, 26, 38, 36, 22, 0, 1, 7, 23] max:min 39 0
epoch:15, iteration:0
0.5039258599281311 0.5015900731086731 0.4113733768463135
lambda: 0.9455923030604562 1.0868959572807058 0.967511739658838
epoch:15, iteration:5
0.8632652163505554 1.5852181911468506 0.42596298456192017
lambda: 0.9540497002061765 0.9517561314650476 1.094194168328776
epoch:15, iteration:10
0.42859748005867004 0.956174373626709 0.36266613006591797
lambda: 0.9815724951794702 0.9181563235314898 1.10027118128904
epoch:15, iteration:15
0.5229216814041138 0.9442321062088013 0.383176326751709
lambda: 1.1883356533453868 0.8971853482496469 0.9144789984049664
epoch:15, iteration:20
0.5044257044792175 0.7189880609512329 0.40446481108665466
lambda: 0.9953303884992717 0.9604509783871168 1.0442186331136118
epoch:15, iteration:25
0.9862034916877747 0.9226409792900085 0.3594907522201538
lambda: 1.013757348499366 1.0677188398401924 0.9185238116604413
epoch:15, iteration:30
0.4574087858200073 0.5685969591140747 0.3845861554145813
lambda: 1.0642040140955167 0.9024068621441298 1.0333891237603534
epoch:15, iteration:35
0.6087920665740967 1.0637575387954712 0.36860668659210205
lambda: 1.0779219146194614 0.9087078716311028 1.0133702137494356
Epoch Dev:	15
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7537	0.5778	0.5242
Epoch Test:	15
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7581	0.5612	0.5234
--------------------------------------------------------------------
Training Completed!
Processing...
The best Dev epoch is:  11
The best Dev F1 points for Span Nuclearity Relation are:
 0.7555	0.5690	0.5268
Data path: ./data/pickle-data/depth/to_pt/zh-gcdt-hfl-chinese-roberta-wwm-ext/
Model path: depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed111/
Epoch EvalOnly Test:	11
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7716	0.5459	0.5090
Epoch EvalOnly Test:	11	docid:	0
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7560	0.4976	0.4402
Epoch EvalOnly Test:	11	docid:	1
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7597	0.5504	0.5388
Epoch EvalOnly Test:	11	docid:	2
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7722	0.5570	0.4873
Epoch EvalOnly Test:	11	docid:	3
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7717	0.5326	0.5109
Epoch EvalOnly Test:	11	docid:	4
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7921	0.5776	0.5413
Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
args.use_org_Parseval: True
language embedding name:  hfl/chinese-roberta-wwm-ext
Language embedding loaded from pretrained:  hfl/chinese-roberta-wwm-ext
Checking Data...
 英 语 中 动 态 的 象 似 性 分 析 1 . 导 论 从 广 义 的 角 度 来 看 ， 英 语 中 主 要 分 为 三 个 [UNK] 态 [UNK] ： 主 动 态 ， 中 动 态 和 被 动 态 。 英 语 中 动 态 是 一 种 特 殊 的 语 态 形 式 ， 因 为 它 缺 少 施 事 [ 1 ] 。 从 语 义 的 角 度 来 看 ， 英 语 中 动 态 具 有 如 下 特 点 ： 1 ) 非 事 件 性 ； 2 ) 泛 指 性 ； 3 ) 施 动 性 ； 4 ) 情 态 概 念 [ 2 ] 。 在 主 动 态 的 象 似 性 研 究 中 ， 施 事 的 动 作 产 生 无 论 如 何 先 于 过 程 对 受 事 的 影 响 ， 也 就 是 因 ( 施 事 ) 先 于 果 ( 过 程 对 受 事 的 影 响 ) ， 因 此 ， 主 动 态 是 最 符 合 象 似 性 原 则 的 表 达 。 在 被 动 态 结 构 中 ， 施 事 先 于 受 事 ， 明 显 违 背 了 象 似 性 原 则 。 那 么 ， 就 中 动 态 而 言 ， 它 的 语 法 结 构 是 主 动 态 的 ， 但 是 各 参 与 成 分 之 间 的 关 系 是 被 动 态 的 ， 我 们 如 何 从 象 似 性 角 度 来 分 析 它 呢 ？ 本 文 主 要 探 讨 了 英 语 中 动 态 的 象 似 性 特 点 。 本 文 提 出 的 问 题 如 下 ： ① 英 语 中 动 态 是 如 何 遵 守 或 违 背 象 似 性 原 则 的 ？ ② 英 语 中 动 态 违 背 象 似 性 原 则 的 理 据 为 何 ？ 2 . 象 似 性 原 则 2 . 1 . 顺 序 象 似 性 顺 序 象 似 性 可 以 定 义 为 ： 思 维 的 顺 序 与 语 言 单 位 排 列 的 顺 序 象 似 [ 3 ] 。 green ##berg 也 表 示 ： [UNK] 语 言 成 分 的 顺 序 对 应 与 物 理 现 实 经 验 顺 序 或 知 识 顺 序 [UNK] the order of el ##ement ##s in language pa ##ral ##le ##ls that in ph ##ys ##ical ex ##per ##ience or the order of know ##led ##ge [ 4 ] 。 文 旭 ( 2009 ) 将 这 一 原 则 进 一 步 分 为 两 个 原 则 [ 5 ] ： 1 ) 线 性 序 列 时 间 原 则 ： 连 贯 话 语 中 分 句 的 顺 序 对 应 于 其 所 描 写 的 事 件 发 生 的 时 间 顺 序 。 比 如 [UNK] i cam ##e , i sa ##w , i con ##que ##red . [UNK] 又 比 如 ： max hit harry and harry hit max 表 示 max hit harry 在 先 ， harry hit max 在 后 。 而 max and harry hit ea ##ch other 则 没 有 体 现 出 这 种 时 间 先 后 的 概 念 。 2 ) 线 性 序 列 信 息 原 则 。 该 原 则 主 要 是 与 信 息 的 分 配 相 联 系 。 谈 到 信 息 分 配 ， 我 们 主 要 采 用 的 是 hall ##ida ##y 系 统 功 能 语 言 学 关 于 信 息 分 布 的 观 点 。 hall ##ida ##y & matt ##hi ##ess ##en [ 1 ] 认 为 主 位 ( the ##me ) 是 句 中 信 息 的 起 点 ， 是 整 个 小 句 所 关 注 和 讨 论 的 ， 也 是 小 句 得 以 展 开 的 背 景 。 小 句 中 发 展 主 位 的 部 分 被 称 之 为 述 位 ( r ##he ##me ) 。 通 常 在 陈 述 句 中 非 标 记 性 主 位 ( u ##nm ##ark ##ed the ##me ) 与 主 语 重 合 ， 主 语 以 外 的 任 何 成 分 都 是 标 记 性 主 位 ( mark ##ed the ##me ) [ 1 ] 。 就 信 息 结 构 在 语 言 结 构 中 的 体 现 而 言 ， 非 标 记 式 匹 配 是 ： 与 主 语 重 合 的 非 标 记 性 主 位 传 达 的 是 旧 信 息 ， 而 述 位 传 达 的 是 新 信 息 。 在 语 言 使 用 过 程 中 ， 我 们 会 调 整 主 位 的 实 现 成 分 重 新 分 配 信 息 量 ， 这 样 ， 标 记 性 或 非 象 似 性 表 达 就 产 生 了 。 线 性 序 列 信 息 原 则 表 示 最 熟 悉 的 已 知 背 景 信 息 先 出 现 ， 最 不 熟 悉 的 新 信 息 后 出 现 。 hall ##ida ##y & matt ##hi ##ess ##en [ 1 ] 认 为 主 位 表 达 旧 信 息 ， 述 位 表 达 新 信 息 是 非 标 记 性 信 息 匹 配 结 构 ； 但 是 在 语 言 使 用 中 ， 我 们 可 以 利 用 主 谓 结 构 和 信 息 结 构 [ 的 错 配 ( mi ##sm ##at ##ch ) ] 来 达 到 意 想 不 到 的 修 辞 效 果 。 hall ##ida ##y 也 曾 明 确 表 示 了 象 似 性 的 概 念 ， 他 说 ： 在 语 言 表 达 中 存 在 以 下 规 律 ， 即 信 息 流 沿 着 从 旧 信 息 ( 主 位 ) 流 向 新 信 息 ( 述 位 ) 的 方 向 移 动 ， 这 种 遵 循 时 间 顺 序 的 移 动 象 似 性 地 始 解 了 信 息 流 的 传 播 方 向 ( there is a mo ##ve ##ment from a gi ##ven the ##me ( back ##ground ) to r ##he ##ma ##tic new ( for ##eg ##ro ##und ) ; this mo ##ve ##ment in time con ##st ##ru ##es icon ##ical ##ly the f ##low of information ) [ 6 ] 。 2 . 2 . 距 离 象 似 性 根 据 文 旭 [ 5 ] ， 距 离 象 似 性 定 义 如 下 ： 概 念 间 的 距 离 对 应 于 语 言 成 分 之 间 的 距 离 。 ha ##ima ##n [ 7 ] 认 为 两 个 观 点 在 概 念 的 接 近 必 须 满 足 以 下 四 个 条 件 ： 1 ) 彼 此 享 有 语 义 特 点 或 部 分 ； 2 ) 相 互 影 响 ； 3 ) 在 现 实 中 不 可 分 离 ； 4 ) 不 管 在 现 实 中 可 不 可 以 分 离 ， 均 视 为 一 个 整 体 。 2 . 3 . 数 量 象 似 性 根 据 王 寅 [ 8 ] 数 量 象 似 性 的 定 义 为 ： 语 言 单 位 的 数 量 与 所 表 示 的 概 念 的 量 和 复 杂 程 度 成 正 比 象 似 ， 与 可 预 测 度 成 反 比 。 数 量 象 似 性 的 认 知 基 础 是 ： 语 言 单 位 数 量 一 多 ， 就 会 更 多 地 引 起 人 们 的 注 意 力 ， 心 智 加 工 也 就 更 复 杂 ， 传 递 的 信 息 量 自 然 也 会 更 多 [ 9 ] 。 gi ##vo ##n [ 10 ] 指 出 ， 信 息 处 理 过 程 中 投 入 更 多 的 心 智 努 力 ( men ##tal ef ##fo ##rt ) 需 要 更 多 的 语 言 编 码 材 料 来 表 达 。 语 言 的 每 一 个 单 位 得 以 被 应 用 都 有 它 能 被 使 用 的 价 值 ， 这 个 价 值 就 是 传 递 相 应 的 意 义 ， 因 此 ， 语 言 单 位 越 多 ， 必 定 要 传 递 更 多 的 概 念 。 2 . 4 . 对 称 象 似 性 根 据 ha ##ima ##n [ 7 ] 对 称 象 似 性 指 的 是 语 言 形 式 的 对 称 或 非 对 称 形 式 表 达 了 语 言 形 式 各 部 分 代 表 的 概 念 之 间 存 在 的 对 称 关 系 或 不 对 称 关 系 ( ( a ) s ##ym ##me ##try of form will re ##fl ##ect con ##cept ##ual ( a ) s ##ym ##me ##try ) 。 比 如 sim ##il ##ari ##ty 表 达 的 是 绝 对 对 称 性 概 念 。 harry is sim ##il ##ar to max 与 max is sim ##il ##ar to harry 是 完 全 对 称 的 。 like 表 示 的 不 是 绝 对 对 称 概 念 ， 比 如 max like ##s harry 并 不 与 harry like ##s max 对 称 。 ha ##ima ##n 通 过 多 语 言 对 比 ， 发 现 and 也 可 以 被 用 作 因 果 丛 句 和 条 件 丛 句 。 比 如 ： sam ##my [UNK] s ma ##d and i [UNK] m gl ##ad 和 he come ##s , i will stay 。 在 这 两 句 中 ， su ##mmy [UNK] ma ##d 和 he come ##s 被 看 作 是 表 原 因 的 小 句 。 ha ##ima ##n [ 7 ] 认 为 这 是 一 种 概 念 对 称 的 体 现 ， 因 为 根 据 时 间 的 线 性 特 点 ， 最 先 发 生 的 可 以 看 作 是 背 景 ， 原 因 ， 条 件 。
... ...
That's great! No error found!
All train sample number: 40
Model save path depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed222/
Finetune from path None
Total trainable parameter number is:  93938722
self.use_org_Parseval:  True
whole iter list [5, 21, 8, 22, 17, 9, 20, 25, 37, 4] max:min 39 0
epoch:1, iteration:0
3.999422311782837 6.081489562988281 1.7833367586135864
epoch:1, iteration:5
3.5684375762939453 4.149359226226807 1.5961904525756836
lambda: 1.0145172341126254 0.958030147142646 1.027452618744729
epoch:1, iteration:10
3.575833559036255 4.628017902374268 1.479993462562561
lambda: 1.0163855447920094 0.9924531610822738 0.9911612941257171
epoch:1, iteration:15
3.1568825244903564 4.362453937530518 1.4705207347869873
lambda: 1.0394086656582184 0.9961507117508249 0.9644406225909565
epoch:1, iteration:20
2.0857043266296387 3.4163644313812256 1.224393367767334
lambda: 1.0528880044104452 1.0322141790764996 0.914897816513055
epoch:1, iteration:25
2.3399970531463623 2.894132137298584 1.236250400543213
lambda: 0.9284898841999594 1.0405660106554027 1.0309441051446382
epoch:1, iteration:30
2.422423839569092 3.9592947959899902 1.219712257385254
lambda: 0.946595921507361 1.0514070916139375 1.0019969868787013
epoch:1, iteration:35
2.6077816486358643 3.2139811515808105 1.2209594249725342
lambda: 1.081607405937842 0.96336131104626 0.9550312830158985
Epoch Dev:	1
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.5523	0.3518	0.3052
Epoch Test:	1
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.5836	0.3543	0.2941
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed222/Epoch_1.torchsave
whole iter list [24, 3, 35, 28, 18, 4, 0, 2, 37, 31] max:min 39 0
epoch:2, iteration:0
2.112206220626831 2.2871809005737305 1.137885332107544
lambda: 0.9658806624033134 1.1343323270157484 0.8997870105809384
epoch:2, iteration:5
2.0228769779205322 2.5849547386169434 1.0132695436477661
lambda: 0.7464960306836604 1.3710346181356952 0.8824693511806443
epoch:2, iteration:10
1.7030715942382812 2.437309741973877 0.9731916785240173
lambda: 0.9355045181157214 1.0857958026004761 0.9786996792838025
epoch:2, iteration:15
2.1003520488739014 2.5838048458099365 0.9738397598266602
lambda: 1.1403604441134403 0.9226874061760425 0.9369521497105175
epoch:2, iteration:20
1.8855406045913696 2.640406370162964 0.9514110684394836
lambda: 0.9675542748724626 0.9959429330638087 1.0365027920637289
epoch:2, iteration:25
2.593886613845825 2.1839683055877686 0.934168815612793
lambda: 1.0675285483216226 0.9637003467138052 0.9687711049645723
epoch:2, iteration:30
1.5562595129013062 2.6693155765533447 0.9164266586303711
lambda: 0.9177345439650393 1.0335539970664267 1.0487114589685342
epoch:2, iteration:35
1.8489136695861816 2.5302157402038574 0.9106742143630981
lambda: 1.1873642473262778 0.9093019490167299 0.9033338036569922
Epoch Dev:	2
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.6482	0.4398	0.3808
Epoch Test:	2
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.6601	0.4200	0.3597
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed222/Epoch_2.torchsave
whole iter list [29, 20, 2, 32, 9, 35, 4, 18, 39, 33] max:min 39 0
epoch:3, iteration:0
1.3698713779449463 2.2403087615966797 0.9025131464004517
lambda: 1.020889380149974 1.0387313915813405 0.9403792282686854
epoch:3, iteration:5
0.9265100955963135 2.3247146606445312 0.8810095191001892
lambda: 1.354551584131665 0.7629376387058466 0.8825107771624885
epoch:3, iteration:10
1.707208275794983 2.1270387172698975 0.7805211544036865
lambda: 0.9709514748839341 1.1444626141486909 0.8845859109673753
epoch:3, iteration:15
1.8574907779693604 2.144777536392212 0.8282700181007385
lambda: 0.980612456138027 0.9873206473033489 1.032066896558624
epoch:3, iteration:20
1.5219072103500366 1.9552645683288574 0.8806275129318237
lambda: 1.0051897582453568 0.9478089142972327 1.0470013274574104
epoch:3, iteration:25
1.915883183479309 1.1942834854125977 0.7399206161499023
lambda: 1.005195461909897 0.8818449547547319 1.1129595833353711
epoch:3, iteration:30
1.2137458324432373 1.828420639038086 0.799080491065979
lambda: 1.0207580804874272 0.998072467113622 0.9811694523989509
epoch:3, iteration:35
1.4578466415405273 2.1474733352661133 0.7442606687545776
lambda: 0.8954314516585135 0.9793489560083064 1.1252195923331803
Epoch Dev:	3
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7010	0.4828	0.4257
Epoch Test:	3
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.6817	0.4478	0.3966
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed222/Epoch_3.torchsave
whole iter list [35, 25, 29, 28, 0, 20, 22, 39, 23, 7] max:min 39 0
epoch:4, iteration:0
1.197434425354004 1.9223124980926514 0.7688506841659546
lambda: 1.1867697679540725 0.9312802395025697 0.8819499925433578
epoch:4, iteration:5
1.3165662288665771 1.9772919416427612 0.7287648916244507
lambda: 0.7194508494510635 1.3313405864657633 0.9492085640831728
epoch:4, iteration:10
1.4658311605453491 2.0145108699798584 0.8148216605186462
lambda: 1.0727141832360936 0.996238714107783 0.9310471026561237
epoch:4, iteration:15
1.2344095706939697 1.9035212993621826 0.7686079740524292
lambda: 0.9933682302276986 0.9366475691439675 1.069984200628334
epoch:4, iteration:20
1.1762560606002808 1.8435693979263306 0.6805270910263062
lambda: 1.0130471573114044 0.9545644621886927 1.0323883804999028
epoch:4, iteration:25
1.190625548362732 1.5733931064605713 0.808673620223999
lambda: 0.8978657885071542 0.9949791528204558 1.1071550586723902
epoch:4, iteration:30
1.0843355655670166 2.0245766639709473 0.7449276447296143
lambda: 0.9767928500251197 0.9303582172617941 1.0928489327130857
epoch:4, iteration:35
1.4221380949020386 2.2438502311706543 0.7391315698623657
lambda: 1.1345993915408354 0.9043529200301245 0.9610476884290401
Epoch Dev:	4
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7018	0.5066	0.4485
Epoch Test:	4
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7149	0.4721	0.4263
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed222/Epoch_4.torchsave
whole iter list [0, 19, 4, 3, 10, 2, 15, 17, 1, 30] max:min 39 0
epoch:5, iteration:0
1.0400047302246094 1.8322962522506714 0.7634776830673218
lambda: 1.0434910713424586 0.9770053706333781 0.9795035580241631
epoch:5, iteration:5
1.227211356163025 1.6521795988082886 0.7084963321685791
lambda: 1.1284683970749905 1.05153763688266 0.8199939660423498
epoch:5, iteration:10
1.2902530431747437 2.0959582328796387 0.7483898997306824
lambda: 0.9065226736110817 0.987467932207056 1.106009394181862
epoch:5, iteration:15
1.0544987916946411 1.6407439708709717 0.6372101306915283
lambda: 0.9646472736130067 1.0671354446631216 0.9682172817238717
epoch:5, iteration:20
1.4021871089935303 1.969200849533081 0.7173550724983215
lambda: 1.1117735725140065 0.9894194219799737 0.89880700550602
epoch:5, iteration:25
1.4017333984375 1.431792974472046 0.6213392019271851
lambda: 1.418324500937456 0.7334166260062742 0.8482588730562695
epoch:5, iteration:30
0.9066042900085449 1.636889934539795 0.6642972230911255
lambda: 0.9990519234976373 0.9584127178388359 1.0425353586635266
epoch:5, iteration:35
1.7862428426742554 0.9247483611106873 0.5398973226547241
lambda: 0.9709265765363592 1.085090956426179 0.9439824670374617
Epoch Dev:	5
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7168	0.5075	0.4600
Epoch Test:	5
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7302	0.5000	0.4586
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed222/Epoch_5.torchsave
whole iter list [37, 8, 25, 6, 12, 1, 38, 9, 16, 22] max:min 39 0
epoch:6, iteration:0
1.1893548965454102 1.5167797803878784 0.6673314571380615
lambda: 1.0703926951660612 0.8626255084684092 1.0669817963655301
epoch:6, iteration:5
0.7678371071815491 1.7859917879104614 0.551429033279419
lambda: 1.0933240333015608 0.9089409639547358 0.9977350027437033
epoch:6, iteration:10
0.8637475967407227 1.4401570558547974 0.6632866263389587
lambda: 1.1226152770249436 1.0841870122762713 0.7931977106987852
epoch:6, iteration:15
0.9386644959449768 1.2633227109909058 0.6543549299240112
lambda: 1.0386856619922258 0.8448762683342309 1.1164380696735432
epoch:6, iteration:20
0.9929901957511902 1.538270354270935 0.6380870342254639
lambda: 1.0123957715185243 0.9367827580802586 1.0508214704012175
epoch:6, iteration:25
0.7210729122161865 1.5635700225830078 0.6843845844268799
lambda: 0.94700197123627 1.0844484740936726 0.9685495546700574
epoch:6, iteration:30
1.0425729751586914 1.4505268335342407 0.5738264322280884
lambda: 1.0264824816568192 1.0534702066208388 0.920047311722342
epoch:6, iteration:35
0.9914991855621338 1.4739603996276855 0.5213804841041565
lambda: 1.001113967164472 1.0220232349729137 0.9768627978626143
Epoch Dev:	6
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7309	0.5251	0.4705
Epoch Test:	6
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7284	0.5135	0.4595
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed222/Epoch_6.torchsave
whole iter list [4, 30, 32, 22, 3, 26, 25, 9, 12, 24] max:min 39 0
epoch:7, iteration:0
0.7639170289039612 1.4324393272399902 0.5244027972221375
lambda: 0.9261788679591868 1.072061771379996 1.0017593606608175
epoch:7, iteration:5
1.028090238571167 1.4372767210006714 0.5110222697257996
lambda: 0.9235323269927277 0.887699911599398 1.1887677614078747
epoch:7, iteration:10
0.8833203911781311 1.4009921550750732 0.5762202739715576
lambda: 0.9320366988113964 0.9838944431951759 1.0840688579934274
epoch:7, iteration:15
1.0288273096084595 1.5070279836654663 0.6741595268249512
lambda: 1.0480227069239954 0.9490716326058026 1.0029056604702018
epoch:7, iteration:20
0.9029386043548584 1.3409062623977661 0.6064783334732056
lambda: 0.7871429693861488 1.4081094917774146 0.8047475388364366
epoch:7, iteration:25
0.8625845313072205 1.3488355875015259 0.529123067855835
lambda: 0.9636431339415489 1.0288197226513935 1.0075371434070575
epoch:7, iteration:30
0.9589758515357971 1.695698618888855 0.6350319385528564
lambda: 1.0541951082788286 0.9450377648376642 1.0007671268835068
epoch:7, iteration:35
1.1053014993667603 1.7471110820770264 0.5034358501434326
lambda: 0.7880104067463206 1.3850503547726 0.8269392384810791
Epoch Dev:	7
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7344	0.5347	0.4943
Epoch Test:	7
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7437	0.5306	0.4784
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed222/Epoch_7.torchsave
whole iter list [9, 3, 7, 15, 6, 4, 24, 10, 5, 13] max:min 39 0
epoch:8, iteration:0
1.355981469154358 1.0604758262634277 0.5181459188461304
lambda: 0.9952381566866425 1.0595544500857477 0.9452073932276095
epoch:8, iteration:5
0.7492912411689758 1.3931710720062256 0.4852859377861023
lambda: 0.7891265893779243 1.399628149429794 0.8112452611922819
epoch:8, iteration:10
0.9015894532203674 1.1429636478424072 0.5550469160079956
lambda: 0.9471334274174651 1.0106104940980167 1.0422560784845183
epoch:8, iteration:15
0.6136695146560669 1.421243667602539 0.5636945962905884
lambda: 0.9301145687655219 0.9866522320626265 1.0832331991718518
epoch:8, iteration:20
0.5812652111053467 1.2175642251968384 0.5298636555671692
lambda: 1.0265617334022454 0.9471483681157279 1.0262898984820268
epoch:8, iteration:25
0.9139031767845154 1.2410697937011719 0.4334353804588318
lambda: 0.992338917082362 0.913458216077291 1.0942028668403467
epoch:8, iteration:30
1.0511640310287476 0.5734298229217529 0.4445141553878784
lambda: 0.9419787564436422 0.975839774990816 1.082181468565542
epoch:8, iteration:35
1.1539369821548462 1.3955426216125488 0.4822542071342468
lambda: 1.1984829921691686 0.9754985693331113 0.8260184384977203
Epoch Dev:	8
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7353	0.5365	0.4855
Epoch Test:	8
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7509	0.5441	0.4982
whole iter list [10, 34, 22, 14, 13, 0, 33, 3, 32, 15] max:min 39 0
epoch:9, iteration:0
0.9183400273323059 1.6000134944915771 0.5403989553451538
lambda: 1.1833192702490138 0.8420181810551798 0.9746625486958066
epoch:9, iteration:5
0.5816309452056885 1.2098418474197388 0.5439885854721069
lambda: 0.8596385334181997 1.0810098805036548 1.0593515860781455
epoch:9, iteration:10
0.5428056120872498 1.0387014150619507 0.5200852155685425
lambda: 1.0541239493616616 0.8137735363541964 1.1321025142841419
epoch:9, iteration:15
0.8907536864280701 1.076602816581726 0.5243767499923706
lambda: 1.4305581160176086 0.7857381733586916 0.7837037106237004
epoch:9, iteration:20
0.7566020488739014 1.2958788871765137 0.45437806844711304
lambda: 0.8897470378065518 1.1410262938568265 0.9692266683366214
epoch:9, iteration:25
0.6960570216178894 1.0933547019958496 0.49107396602630615
lambda: 0.9099791712153298 1.0806546093741858 1.0093662194104847
epoch:9, iteration:30
0.9991841912269592 1.4833215475082397 0.46230655908584595
lambda: 1.2270164604459948 0.7615539302282047 1.0114296093258008
epoch:9, iteration:35
0.775762140750885 1.209118366241455 0.4295496344566345
lambda: 1.0811336434572918 0.8792053794619078 1.0396609770808003
Epoch Dev:	9
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7599	0.5550	0.5145
Epoch Test:	9
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7455	0.5369	0.4964
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed222/Epoch_9.torchsave
whole iter list [22, 5, 12, 24, 25, 19, 4, 14, 3, 9] max:min 39 0
epoch:10, iteration:0
1.0219426155090332 1.9558897018432617 0.49525654315948486
lambda: 0.6391078453556513 1.6250366963644685 0.73585545827988
epoch:10, iteration:5
0.6118096709251404 1.0271648168563843 0.5460317730903625
lambda: 1.0869048865251323 1.051297158632605 0.8617979548422625
epoch:10, iteration:10
0.5194248557090759 1.2496627569198608 0.487352192401886
lambda: 1.4225090572351544 0.8423469241259208 0.7351440186389245
epoch:10, iteration:15
0.6696072220802307 1.2449308633804321 0.45241138339042664
lambda: 1.362390906881729 0.8820139203256564 0.7555951727926147
epoch:10, iteration:20
0.5830292701721191 1.2596582174301147 0.42032450437545776
lambda: 0.9970188153244788 1.0200431602342455 0.9829380244412758
epoch:10, iteration:25
0.6107479333877563 1.0241084098815918 0.4933815896511078
lambda: 1.0644428484009127 0.9088900654759587 1.0266670861231282
epoch:10, iteration:30
0.7882064580917358 1.363698124885559 0.49211233854293823
lambda: 0.506857835547143 1.7182685431041809 0.7748736213486757
epoch:10, iteration:35
0.6475090980529785 1.1384902000427246 0.47599178552627563
lambda: 0.8933680820051668 1.021028275368453 1.0856036426263798
Epoch Dev:	10
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7555	0.5594	0.5075
Epoch Test:	10
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7572	0.5522	0.5063
whole iter list [28, 6, 11, 7, 0, 2, 35, 39, 18, 29] max:min 39 0
epoch:11, iteration:0
0.7410414218902588 0.3684020936489105 0.37466922402381897
lambda: 1.178019535211557 0.9620261543250812 0.8599543104633616
epoch:11, iteration:5
0.7183004021644592 0.9697998762130737 0.4646678566932678
lambda: 0.8588909099928231 0.9294626476514829 1.2116464423556939
epoch:11, iteration:10
0.7982823252677917 1.4412187337875366 0.411169171333313
lambda: 1.0793811756264022 0.8384393944379057 1.0821794299356922
epoch:11, iteration:15
0.5910682082176208 1.1609690189361572 0.47997981309890747
lambda: 0.8408182963571331 1.5648761395918223 0.5943055640510445
epoch:11, iteration:20
0.6279175877571106 1.1948899030685425 0.4097791314125061
lambda: 0.9408033306379247 0.9406572787372884 1.118539390624787
epoch:11, iteration:25
0.8286898732185364 1.462766408920288 0.5020257234573364
lambda: 1.2324890170740954 0.8774287630841461 0.8900822198417587
epoch:11, iteration:30
0.6144100427627563 0.9360887408256531 0.3842921853065491
lambda: 0.9907561151370793 1.0381934424225296 0.9710504424403908
epoch:11, iteration:35
0.8361037969589233 1.0368975400924683 0.432195782661438
lambda: 0.9409347952226911 1.1123371468181054 0.9467280579592037
Epoch Dev:	11
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7573	0.5708	0.5189
Epoch Test:	11
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7482	0.5423	0.4964
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed222/Epoch_11.torchsave
whole iter list [36, 33, 16, 6, 24, 0, 15, 12, 3, 32] max:min 39 0
epoch:12, iteration:0
0.4801047444343567 1.0496025085449219 0.40977028012275696
lambda: 1.0876341806211436 1.0873841079048199 0.8249817114740362
epoch:12, iteration:5
0.5976835489273071 1.1168946027755737 0.4413936734199524
lambda: 0.976370195887214 0.9987265250514438 1.0249032790613428
epoch:12, iteration:10
0.6034294962882996 1.153267502784729 0.3839304447174072
lambda: 1.0733797793226645 0.9993268622566518 0.9272933584206836
epoch:12, iteration:15
0.7606543302536011 0.9797746539115906 0.47288620471954346
lambda: 1.1966614609403496 0.8528750709152124 0.9504634681444384
epoch:12, iteration:20
0.4546498656272888 0.9903895854949951 0.3881198763847351
lambda: 1.0243997089706278 1.0591791461636617 0.9164211448657101
epoch:12, iteration:25
0.8254539370536804 1.0582821369171143 0.4005720019340515
lambda: 0.9184362923084305 1.0914847860331927 0.990078921658377
epoch:12, iteration:30
0.7701460719108582 1.1199032068252563 0.4200056195259094
lambda: 0.6409563507948558 1.761769598072319 0.597274051132825
epoch:12, iteration:35
0.5801233649253845 0.9809989333152771 0.47961145639419556
lambda: 0.9224879662497539 1.3563077982243892 0.7212042355258572
Epoch Dev:	12
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7608	0.5664	0.5119
Epoch Test:	12
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7563	0.5441	0.4973
whole iter list [31, 1, 23, 38, 24, 2, 8, 25, 30, 6] max:min 39 0
epoch:13, iteration:0
0.5866650938987732 1.1857109069824219 0.3953000605106354
lambda: 1.0288536816405578 0.8495930950624098 1.1215532232970324
epoch:13, iteration:5
0.5650302767753601 0.8152610659599304 0.42188698053359985
lambda: 1.0908272946407853 0.8364094523695763 1.0727632529896383
epoch:13, iteration:10
0.42587003111839294 1.0013494491577148 0.34865063428878784
lambda: 1.1005430528442257 1.0245217910111615 0.8749351561446128
epoch:13, iteration:15
0.44193658232688904 1.1238104104995728 0.3682761490345001
lambda: 0.9197351530282184 0.9537932397900043 1.1264716071817773
epoch:13, iteration:20
0.5205988883972168 0.8725349307060242 0.45461010932922363
lambda: 0.8566102228341896 1.0689919934070977 1.0743977837587126
epoch:13, iteration:25
0.6185641288757324 0.8257548809051514 0.36527878046035767
lambda: 1.2337554406165288 0.8879418998560901 0.8783026595273813
epoch:13, iteration:30
0.5444909930229187 0.9789940118789673 0.44579917192459106
lambda: 0.5333531933390601 1.8347622380365243 0.6318845686244159
epoch:13, iteration:35
0.49059101939201355 0.5832111239433289 0.43136513233184814
lambda: 0.8907713534221041 1.1844205962999654 0.9248080502779301
Epoch Dev:	13
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7731	0.5814	0.5259
Epoch Test:	13
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7500	0.5414	0.5018
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed222/Epoch_13.torchsave
whole iter list [37, 35, 33, 34, 2, 27, 10, 24, 32, 39] max:min 39 0
epoch:14, iteration:0
0.5064797401428223 1.028275489807129 0.4005071520805359
lambda: 0.8970387269547041 1.0320542791130123 1.0709069939322835
epoch:14, iteration:5
0.5608177781105042 1.171608567237854 0.36586663126945496
lambda: 0.948392445476548 0.9258112090829611 1.1257963454404911
epoch:14, iteration:10
0.7426522970199585 1.0988891124725342 0.3769042491912842
lambda: 1.0729778964416934 0.8701340030021578 1.056888100556149
epoch:14, iteration:15
0.4880673587322235 0.9805425405502319 0.3804154396057129
lambda: 0.758252838419903 1.373550926265789 0.8681962353143079
epoch:14, iteration:20
0.5421646237373352 0.6985161304473877 0.4238511621952057
lambda: 1.043222470686787 0.9647064194208738 0.992071109892339
epoch:14, iteration:25
0.4126892387866974 0.8684109449386597 0.3428969979286194
lambda: 1.2098445021136222 0.8247855689141683 0.965369928972209
epoch:14, iteration:30
0.28253287076950073 0.826100766658783 0.45853191614151
lambda: 0.9335366020546351 0.9721002501108159 1.094363147834549
epoch:14, iteration:35
0.5330861806869507 1.082335114479065 0.35224011540412903
lambda: 1.072318089948506 0.8657146031109924 1.0619673069405018
Epoch Dev:	14
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7617	0.5770	0.5180
Epoch Test:	14
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7536	0.5567	0.5144
whole iter list [23, 29, 20, 15, 4, 18, 10, 1, 12, 34] max:min 39 0
epoch:15, iteration:0
0.5887272953987122 1.047231674194336 0.43406105041503906
lambda: 1.0247338517706464 0.9716877097276174 1.0035784385017366
epoch:15, iteration:5
0.6601213812828064 1.1080431938171387 0.40804144740104675
lambda: 0.8329181256535745 1.3864452257767808 0.7806366485696444
epoch:15, iteration:10
0.47577980160713196 0.7238160967826843 0.468630850315094
lambda: 0.9544529202624299 1.274617456881748 0.770929622855822
epoch:15, iteration:15
0.8626336455345154 1.679205060005188 0.4018692672252655
lambda: 1.3996233370447098 0.7134908759909346 0.8868857869643552
epoch:15, iteration:20
0.45064809918403625 0.8718464374542236 0.3286605477333069
lambda: 0.9033596477719815 0.963515405112976 1.1331249471150426
epoch:15, iteration:25
0.7667274475097656 0.8335161209106445 0.3964054584503174
lambda: 1.0251317502783484 0.9661701535607511 1.0086980961609007
epoch:15, iteration:30
0.33411604166030884 0.9845919609069824 0.3545437455177307
lambda: 1.048260765029604 1.014300419528964 0.9374388154414321
epoch:15, iteration:35
0.44470226764678955 0.7913592457771301 0.4463531970977783
lambda: 1.1986039900792544 0.793172138835716 1.0082238710850293
Epoch Dev:	15
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7696	0.5805	0.5251
Epoch Test:	15
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7527	0.5468	0.5099
--------------------------------------------------------------------
Training Completed!
Processing...
The best Dev epoch is:  13
The best Dev F1 points for Span Nuclearity Relation are:
 0.7731	0.5814	0.5259
Data path: ./data/pickle-data/depth/to_pt/zh-gcdt-hfl-chinese-roberta-wwm-ext/
Model path: depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed222/
Epoch EvalOnly Test:	13
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7500	0.5414	0.5018
Epoch EvalOnly Test:	13	docid:	0
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7512	0.5072	0.4402
Epoch EvalOnly Test:	13	docid:	1
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7287	0.5349	0.5000
Epoch EvalOnly Test:	13	docid:	2
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7278	0.5127	0.5000
Epoch EvalOnly Test:	13	docid:	3
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7446	0.5652	0.5000
Epoch EvalOnly Test:	13	docid:	4
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7822	0.5710	0.5479
Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
args.use_org_Parseval: True
language embedding name:  hfl/chinese-roberta-wwm-ext
Language embedding loaded from pretrained:  hfl/chinese-roberta-wwm-ext
Checking Data...
 英 语 中 动 态 的 象 似 性 分 析 1 . 导 论 从 广 义 的 角 度 来 看 ， 英 语 中 主 要 分 为 三 个 [UNK] 态 [UNK] ： 主 动 态 ， 中 动 态 和 被 动 态 。 英 语 中 动 态 是 一 种 特 殊 的 语 态 形 式 ， 因 为 它 缺 少 施 事 [ 1 ] 。 从 语 义 的 角 度 来 看 ， 英 语 中 动 态 具 有 如 下 特 点 ： 1 ) 非 事 件 性 ； 2 ) 泛 指 性 ； 3 ) 施 动 性 ； 4 ) 情 态 概 念 [ 2 ] 。 在 主 动 态 的 象 似 性 研 究 中 ， 施 事 的 动 作 产 生 无 论 如 何 先 于 过 程 对 受 事 的 影 响 ， 也 就 是 因 ( 施 事 ) 先 于 果 ( 过 程 对 受 事 的 影 响 ) ， 因 此 ， 主 动 态 是 最 符 合 象 似 性 原 则 的 表 达 。 在 被 动 态 结 构 中 ， 施 事 先 于 受 事 ， 明 显 违 背 了 象 似 性 原 则 。 那 么 ， 就 中 动 态 而 言 ， 它 的 语 法 结 构 是 主 动 态 的 ， 但 是 各 参 与 成 分 之 间 的 关 系 是 被 动 态 的 ， 我 们 如 何 从 象 似 性 角 度 来 分 析 它 呢 ？ 本 文 主 要 探 讨 了 英 语 中 动 态 的 象 似 性 特 点 。 本 文 提 出 的 问 题 如 下 ： ① 英 语 中 动 态 是 如 何 遵 守 或 违 背 象 似 性 原 则 的 ？ ② 英 语 中 动 态 违 背 象 似 性 原 则 的 理 据 为 何 ？ 2 . 象 似 性 原 则 2 . 1 . 顺 序 象 似 性 顺 序 象 似 性 可 以 定 义 为 ： 思 维 的 顺 序 与 语 言 单 位 排 列 的 顺 序 象 似 [ 3 ] 。 green ##berg 也 表 示 ： [UNK] 语 言 成 分 的 顺 序 对 应 与 物 理 现 实 经 验 顺 序 或 知 识 顺 序 [UNK] the order of el ##ement ##s in language pa ##ral ##le ##ls that in ph ##ys ##ical ex ##per ##ience or the order of know ##led ##ge [ 4 ] 。 文 旭 ( 2009 ) 将 这 一 原 则 进 一 步 分 为 两 个 原 则 [ 5 ] ： 1 ) 线 性 序 列 时 间 原 则 ： 连 贯 话 语 中 分 句 的 顺 序 对 应 于 其 所 描 写 的 事 件 发 生 的 时 间 顺 序 。 比 如 [UNK] i cam ##e , i sa ##w , i con ##que ##red . [UNK] 又 比 如 ： max hit harry and harry hit max 表 示 max hit harry 在 先 ， harry hit max 在 后 。 而 max and harry hit ea ##ch other 则 没 有 体 现 出 这 种 时 间 先 后 的 概 念 。 2 ) 线 性 序 列 信 息 原 则 。 该 原 则 主 要 是 与 信 息 的 分 配 相 联 系 。 谈 到 信 息 分 配 ， 我 们 主 要 采 用 的 是 hall ##ida ##y 系 统 功 能 语 言 学 关 于 信 息 分 布 的 观 点 。 hall ##ida ##y & matt ##hi ##ess ##en [ 1 ] 认 为 主 位 ( the ##me ) 是 句 中 信 息 的 起 点 ， 是 整 个 小 句 所 关 注 和 讨 论 的 ， 也 是 小 句 得 以 展 开 的 背 景 。 小 句 中 发 展 主 位 的 部 分 被 称 之 为 述 位 ( r ##he ##me ) 。 通 常 在 陈 述 句 中 非 标 记 性 主 位 ( u ##nm ##ark ##ed the ##me ) 与 主 语 重 合 ， 主 语 以 外 的 任 何 成 分 都 是 标 记 性 主 位 ( mark ##ed the ##me ) [ 1 ] 。 就 信 息 结 构 在 语 言 结 构 中 的 体 现 而 言 ， 非 标 记 式 匹 配 是 ： 与 主 语 重 合 的 非 标 记 性 主 位 传 达 的 是 旧 信 息 ， 而 述 位 传 达 的 是 新 信 息 。 在 语 言 使 用 过 程 中 ， 我 们 会 调 整 主 位 的 实 现 成 分 重 新 分 配 信 息 量 ， 这 样 ， 标 记 性 或 非 象 似 性 表 达 就 产 生 了 。 线 性 序 列 信 息 原 则 表 示 最 熟 悉 的 已 知 背 景 信 息 先 出 现 ， 最 不 熟 悉 的 新 信 息 后 出 现 。 hall ##ida ##y & matt ##hi ##ess ##en [ 1 ] 认 为 主 位 表 达 旧 信 息 ， 述 位 表 达 新 信 息 是 非 标 记 性 信 息 匹 配 结 构 ； 但 是 在 语 言 使 用 中 ， 我 们 可 以 利 用 主 谓 结 构 和 信 息 结 构 [ 的 错 配 ( mi ##sm ##at ##ch ) ] 来 达 到 意 想 不 到 的 修 辞 效 果 。 hall ##ida ##y 也 曾 明 确 表 示 了 象 似 性 的 概 念 ， 他 说 ： 在 语 言 表 达 中 存 在 以 下 规 律 ， 即 信 息 流 沿 着 从 旧 信 息 ( 主 位 ) 流 向 新 信 息 ( 述 位 ) 的 方 向 移 动 ， 这 种 遵 循 时 间 顺 序 的 移 动 象 似 性 地 始 解 了 信 息 流 的 传 播 方 向 ( there is a mo ##ve ##ment from a gi ##ven the ##me ( back ##ground ) to r ##he ##ma ##tic new ( for ##eg ##ro ##und ) ; this mo ##ve ##ment in time con ##st ##ru ##es icon ##ical ##ly the f ##low of information ) [ 6 ] 。 2 . 2 . 距 离 象 似 性 根 据 文 旭 [ 5 ] ， 距 离 象 似 性 定 义 如 下 ： 概 念 间 的 距 离 对 应 于 语 言 成 分 之 间 的 距 离 。 ha ##ima ##n [ 7 ] 认 为 两 个 观 点 在 概 念 的 接 近 必 须 满 足 以 下 四 个 条 件 ： 1 ) 彼 此 享 有 语 义 特 点 或 部 分 ； 2 ) 相 互 影 响 ； 3 ) 在 现 实 中 不 可 分 离 ； 4 ) 不 管 在 现 实 中 可 不 可 以 分 离 ， 均 视 为 一 个 整 体 。 2 . 3 . 数 量 象 似 性 根 据 王 寅 [ 8 ] 数 量 象 似 性 的 定 义 为 ： 语 言 单 位 的 数 量 与 所 表 示 的 概 念 的 量 和 复 杂 程 度 成 正 比 象 似 ， 与 可 预 测 度 成 反 比 。 数 量 象 似 性 的 认 知 基 础 是 ： 语 言 单 位 数 量 一 多 ， 就 会 更 多 地 引 起 人 们 的 注 意 力 ， 心 智 加 工 也 就 更 复 杂 ， 传 递 的 信 息 量 自 然 也 会 更 多 [ 9 ] 。 gi ##vo ##n [ 10 ] 指 出 ， 信 息 处 理 过 程 中 投 入 更 多 的 心 智 努 力 ( men ##tal ef ##fo ##rt ) 需 要 更 多 的 语 言 编 码 材 料 来 表 达 。 语 言 的 每 一 个 单 位 得 以 被 应 用 都 有 它 能 被 使 用 的 价 值 ， 这 个 价 值 就 是 传 递 相 应 的 意 义 ， 因 此 ， 语 言 单 位 越 多 ， 必 定 要 传 递 更 多 的 概 念 。 2 . 4 . 对 称 象 似 性 根 据 ha ##ima ##n [ 7 ] 对 称 象 似 性 指 的 是 语 言 形 式 的 对 称 或 非 对 称 形 式 表 达 了 语 言 形 式 各 部 分 代 表 的 概 念 之 间 存 在 的 对 称 关 系 或 不 对 称 关 系 ( ( a ) s ##ym ##me ##try of form will re ##fl ##ect con ##cept ##ual ( a ) s ##ym ##me ##try ) 。 比 如 sim ##il ##ari ##ty 表 达 的 是 绝 对 对 称 性 概 念 。 harry is sim ##il ##ar to max 与 max is sim ##il ##ar to harry 是 完 全 对 称 的 。 like 表 示 的 不 是 绝 对 对 称 概 念 ， 比 如 max like ##s harry 并 不 与 harry like ##s max 对 称 。 ha ##ima ##n 通 过 多 语 言 对 比 ， 发 现 and 也 可 以 被 用 作 因 果 丛 句 和 条 件 丛 句 。 比 如 ： sam ##my [UNK] s ma ##d and i [UNK] m gl ##ad 和 he come ##s , i will stay 。 在 这 两 句 中 ， su ##mmy [UNK] ma ##d 和 he come ##s 被 看 作 是 表 原 因 的 小 句 。 ha ##ima ##n [ 7 ] 认 为 这 是 一 种 概 念 对 称 的 体 现 ， 因 为 根 据 时 间 的 线 性 特 点 ， 最 先 发 生 的 可 以 看 作 是 背 景 ， 原 因 ， 条 件 。
... ...
That's great! No error found!
All train sample number: 40
Model save path depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed333/
Finetune from path None
Total trainable parameter number is:  93938722
self.use_org_Parseval:  True
whole iter list [31, 33, 9, 20, 23, 34, 32, 6, 37, 11] max:min 39 0
epoch:1, iteration:0
4.496240139007568 6.530926704406738 1.5532820224761963
epoch:1, iteration:5
2.582123279571533 5.458987712860107 1.4711436033248901
lambda: 0.9535294290963942 1.0185036215465544 1.0279669493570516
epoch:1, iteration:10
2.0182106494903564 4.429646015167236 1.3794503211975098
lambda: 1.1323373500132878 0.9306752343762319 0.9369874156104804
epoch:1, iteration:15
2.9160637855529785 3.8291032314300537 1.3174939155578613
lambda: 0.9319946495221761 1.0328550904776388 1.0351502600001856
epoch:1, iteration:20
2.422300338745117 4.113001823425293 1.2548747062683105
lambda: 0.8693929015883598 1.1097921476088752 1.020814950802765
epoch:1, iteration:25
2.915584087371826 2.7411491870880127 1.1115586757659912
lambda: 1.0089202715737358 0.9626828190122108 1.0283969094140533
epoch:1, iteration:30
1.9274981021881104 3.4809200763702393 1.0628156661987305
lambda: 0.9504646226280427 1.0896604083866297 0.9598749689853273
epoch:1, iteration:35
2.1831374168395996 3.659449577331543 1.0836875438690186
lambda: 1.0049350505081933 1.0017882870306944 0.9932766624611126
Epoch Dev:	1
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.6025	0.3544	0.3008
Epoch Test:	1
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.6187	0.3696	0.3058
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed333/Epoch_1.torchsave
whole iter list [7, 3, 13, 14, 32, 34, 18, 22, 25, 12] max:min 39 0
epoch:2, iteration:0
2.360098361968994 3.4622340202331543 1.0614755153656006
lambda: 0.968587647828641 0.9409746822088029 1.090437669962556
epoch:2, iteration:5
1.6925292015075684 3.436241865158081 0.9892913103103638
lambda: 0.997011368202812 1.03541368195043 0.967574949846758
epoch:2, iteration:10
2.123506784439087 2.2940824031829834 0.9974981546401978
lambda: 1.1514375522440685 0.866092803481757 0.9824696442741748
epoch:2, iteration:15
1.6287999153137207 2.766413450241089 0.9383993148803711
lambda: 0.9880618134801522 0.9793340404951921 1.0326041460246556
epoch:2, iteration:20
2.177990436553955 1.5779855251312256 1.1098341941833496
lambda: 1.0213267690595844 0.9833744369901171 0.9952987939502987
epoch:2, iteration:25
1.8974906206130981 2.9717743396759033 0.8578197360038757
lambda: 1.093220711527303 0.9745133998284727 0.9322658886442245
epoch:2, iteration:30
1.9422556161880493 2.7788259983062744 0.8955727219581604
lambda: 1.0857056272560948 0.9645229089182469 0.9497714638256578
epoch:2, iteration:35
1.704457402229309 2.495181083679199 0.8630156517028809
lambda: 1.0340932474646256 0.9442781946444571 1.0216285578909172
Epoch Dev:	2
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.6456	0.3896	0.3483
Epoch Test:	2
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.6574	0.3966	0.3471
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed333/Epoch_2.torchsave
whole iter list [8, 36, 12, 25, 34, 7, 26, 38, 30, 21] max:min 39 0
epoch:3, iteration:0
1.4004427194595337 2.698183059692383 0.7871971130371094
lambda: 0.9655891901136757 1.0073316944773971 1.0270791154089274
epoch:3, iteration:5
1.6204581260681152 2.7286927700042725 0.8134421110153198
lambda: 0.9632039883023749 1.0631799297187687 0.9736160819788563
epoch:3, iteration:10
2.0961453914642334 1.062347650527954 0.7168111205101013
lambda: 1.2177902509604297 0.9178754991647641 0.8643342498748063
epoch:3, iteration:15
1.8877482414245605 2.7105257511138916 0.8659601211547852
lambda: 0.9215827858572726 1.2091358968447197 0.8692813172980078
epoch:3, iteration:20
1.3797566890716553 2.1758227348327637 0.8322132229804993
lambda: 1.004158554369519 1.194513088083677 0.8013283575468036
epoch:3, iteration:25
1.3019295930862427 2.2759222984313965 0.7419769763946533
lambda: 0.9800578391032359 0.9648754380321944 1.0550667228645692
epoch:3, iteration:30
1.6630324125289917 1.1199702024459839 0.9369752407073975
lambda: 0.9847110141922379 0.9712113423132834 1.0440776434944785
epoch:3, iteration:35
1.3185229301452637 2.1744484901428223 0.8323702812194824
lambda: 0.8193341333588743 1.1218336086921292 1.0588322579489968
Epoch Dev:	3
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.6675	0.4565	0.4063
Epoch Test:	3
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.6781	0.4559	0.4038
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed333/Epoch_3.torchsave
whole iter list [10, 16, 23, 2, 27, 11, 21, 32, 0, 38] max:min 39 0
epoch:4, iteration:0
1.704071283340454 2.3924646377563477 0.8038263320922852
lambda: 1.0100608929238668 0.9664909054315504 1.023448201644583
epoch:4, iteration:5
1.324006199836731 1.9829899072647095 0.7763476967811584
lambda: 0.9581975356082776 1.069273662417585 0.9725288019741373
epoch:4, iteration:10
1.3953707218170166 2.1606526374816895 0.6893401145935059
lambda: 1.1838963097263455 0.8965417293742488 0.9195619608994058
epoch:4, iteration:15
1.0477824211120605 1.8573839664459229 0.7372209429740906
lambda: 1.0527741087652516 1.032174233587762 0.9150516576469865
epoch:4, iteration:20
1.251307725906372 0.9739757776260376 0.6344794034957886
lambda: 1.0844465027548795 0.9976185744254599 0.9179349228196609
epoch:4, iteration:25
1.2413605451583862 1.8415651321411133 0.6404303312301636
lambda: 0.9755952159425934 1.0083553566141523 1.0160494274432543
epoch:4, iteration:30
1.4957566261291504 1.7183806896209717 0.6802018880844116
lambda: 0.9511725048513937 1.0014653166770477 1.0473621784715585
epoch:4, iteration:35
1.2427804470062256 1.6984155178070068 0.6219379305839539
lambda: 1.0349937932787934 0.9491303059752128 1.0158759007459934
Epoch Dev:	4
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.6966	0.4679	0.4230
Epoch Test:	4
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.6969	0.4838	0.4308
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed333/Epoch_4.torchsave
whole iter list [11, 4, 33, 38, 13, 22, 5, 20, 21, 28] max:min 39 0
epoch:5, iteration:0
1.09099280834198 1.6923021078109741 0.6833149194717407
lambda: 1.212999764953879 0.8202892095498427 0.9667110254962782
epoch:5, iteration:5
1.6570130586624146 2.4667556285858154 0.6406358480453491
lambda: 0.9918020486479437 1.0322586565835876 0.9759392947684685
epoch:5, iteration:10
1.1385966539382935 1.1526302099227905 0.7216581106185913
lambda: 1.2297318677121003 0.8099733290972397 0.9602948031906597
epoch:5, iteration:15
1.1506147384643555 1.6729005575180054 0.5801288485527039
lambda: 0.9458441045300894 0.9796959816285171 1.074459913841394
epoch:5, iteration:20
1.1699533462524414 1.5319007635116577 0.6940861940383911
lambda: 1.2146998539325435 0.8766825024477852 0.9086176436196713
epoch:5, iteration:25
0.9687981009483337 1.572869062423706 0.6996213793754578
lambda: 1.1071570587333848 0.9731403534829681 0.9197025877836467
epoch:5, iteration:30
0.9925789833068848 1.6614383459091187 0.6472064256668091
lambda: 0.9359468846690534 0.9792185754311747 1.0848345398997719
epoch:5, iteration:35
1.2205320596694946 1.1373193264007568 0.5770053267478943
lambda: 0.8309926749199907 1.2219443257273153 0.9470629993526944
Epoch Dev:	5
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7098	0.5057	0.4547
Epoch Test:	5
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7086	0.4946	0.4496
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed333/Epoch_5.torchsave
whole iter list [31, 14, 3, 30, 24, 8, 13, 23, 2, 25] max:min 39 0
epoch:6, iteration:0
0.9081087708473206 1.9943794012069702 0.5566893815994263
lambda: 1.0427120051196743 1.0892361807327566 0.8680518141475689
epoch:6, iteration:5
1.1343941688537598 1.6675835847854614 0.5746416449546814
lambda: 1.0631708047908246 0.943321099497627 0.9935080957115487
epoch:6, iteration:10
1.6195465326309204 1.276425838470459 0.5736059546470642
lambda: 1.1555131313604248 0.9139647150441764 0.9305221535953986
epoch:6, iteration:15
0.82964688539505 1.4763715267181396 0.6226997375488281
lambda: 1.1589143417125791 0.8415014672288903 0.9995841910585307
epoch:6, iteration:20
0.9532723426818848 1.4103853702545166 0.5540729761123657
lambda: 1.0631738859128554 1.040628997923892 0.8961971161632521
epoch:6, iteration:25
1.1004962921142578 1.893413782119751 0.54815673828125
lambda: 0.7825723857781782 1.369861164490543 0.8475664497312789
epoch:6, iteration:30
0.8529050350189209 1.5498569011688232 0.6011834740638733
lambda: 0.9856664246294353 0.9988500726050695 1.0154835027654951
epoch:6, iteration:35
1.4977823495864868 1.214976191520691 0.6111264228820801
lambda: 1.0288740804100325 1.0358054334924858 0.9353204860974816
Epoch Dev:	6
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7247	0.5365	0.4828
Epoch Test:	6
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7302	0.5207	0.4694
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed333/Epoch_6.torchsave
whole iter list [19, 17, 22, 36, 26, 3, 10, 38, 18, 14] max:min 39 0
epoch:7, iteration:0
0.8036723732948303 1.4392369985580444 0.6230911016464233
lambda: 1.0448617653132508 0.9409581283021891 1.01418010638456
epoch:7, iteration:5
0.8156851530075073 1.0103440284729004 0.6348919868469238
lambda: 1.1233521322524829 0.926295488000443 0.9503523797470739
epoch:7, iteration:10
1.0033079385757446 1.6850959062576294 0.5093837976455688
lambda: 1.0839297556434833 0.9774923035036815 0.9385779408528355
epoch:7, iteration:15
0.9571545124053955 1.4432449340820312 0.6210602521896362
lambda: 0.9302067543225786 1.0655406166153332 1.0042526290620883
epoch:7, iteration:20
0.9249162673950195 1.3066363334655762 0.5342602729797363
lambda: 1.0468065644435642 1.0551201373458552 0.8980732982105808
epoch:7, iteration:25
0.9431518316268921 1.3986765146255493 0.5940552949905396
lambda: 1.1695231917623399 0.8246271422254875 1.005849666012173
epoch:7, iteration:30
0.7760611772537231 1.5395275354385376 0.5838062763214111
lambda: 0.9850436771291169 0.9430525034804045 1.0719038193904784
epoch:7, iteration:35
0.861416757106781 0.9870730042457581 0.5498887300491333
lambda: 1.0353886200725015 0.9329564839434756 1.0316548959840228
Epoch Dev:	7
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7230	0.5347	0.4820
Epoch Test:	7
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7365	0.5216	0.4775
whole iter list [20, 26, 23, 22, 34, 33, 1, 18, 14, 30] max:min 39 0
epoch:8, iteration:0
0.6844285130500793 1.1391199827194214 0.5330569744110107
lambda: 0.9070538301301893 1.0699121701157446 1.0230339997540665
epoch:8, iteration:5
0.8599342107772827 1.5251725912094116 0.5802054405212402
lambda: 0.9444247995514828 1.0240281927015766 1.0315470077469406
epoch:8, iteration:10
0.643951952457428 1.3550878763198853 0.5496063232421875
lambda: 0.8600798396000515 1.0440963805415768 1.0958237798583719
epoch:8, iteration:15
0.6705129742622375 1.2094427347183228 0.5694015026092529
lambda: 0.4956755754874337 1.84588696421837 0.6584374602941964
epoch:8, iteration:20
0.7002800107002258 0.8154022097587585 0.5573786497116089
lambda: 0.9858030671715791 1.004915089868884 1.009281842959537
epoch:8, iteration:25
0.7753781080245972 1.2306569814682007 0.4883500933647156
lambda: 0.9206061495536533 1.140644533995131 0.9387493164512155
epoch:8, iteration:30
0.6860963106155396 0.8428347110748291 0.5658904314041138
lambda: 1.2465723863111817 0.853252358643802 0.900175255045016
epoch:8, iteration:35
0.7448294162750244 1.2118715047836304 0.530073881149292
lambda: 1.0368368984182168 1.0215600799203934 0.9416030216613899
Epoch Dev:	8
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7432	0.5418	0.4881
Epoch Test:	8
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7383	0.5261	0.4784
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed333/Epoch_8.torchsave
whole iter list [28, 6, 38, 32, 3, 25, 30, 24, 4, 10] max:min 39 0
epoch:9, iteration:0
1.2052595615386963 0.5733879804611206 0.4448973536491394
lambda: 1.2217141819348043 0.8029534743369385 0.9753323437282567
epoch:9, iteration:5
0.6783753037452698 1.2356492280960083 0.4888201057910919
lambda: 0.886114729708546 0.9373249722570575 1.1765602980343965
epoch:9, iteration:10
1.2949023246765137 1.0386242866516113 0.4681326150894165
lambda: 1.046468926304328 0.9957838267821787 0.9577472469134933
epoch:9, iteration:15
0.9333229660987854 0.8774667382240295 0.4924076795578003
lambda: 0.9628537945519754 0.9561300277961363 1.0810161776518885
epoch:9, iteration:20
0.7263084053993225 1.4066493511199951 0.5300437211990356
lambda: 0.9460888125003781 0.8804173567741648 1.1734938307254572
epoch:9, iteration:25
0.9817559719085693 1.2299474477767944 0.4709934592247009
lambda: 0.8229664647342763 1.2443022250845892 0.932731310181135
epoch:9, iteration:30
0.734468936920166 1.3202390670776367 0.46740520000457764
lambda: 0.923532583532707 0.9660321635274112 1.1104352529398815
epoch:9, iteration:35
0.5674248933792114 1.2161848545074463 0.47178784012794495
lambda: 0.9439804656755173 1.0683561110012818 0.9876634233232011
Epoch Dev:	9
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7502	0.5567	0.5136
Epoch Test:	9
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7572	0.5342	0.4838
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed333/Epoch_9.torchsave
whole iter list [14, 37, 35, 22, 31, 7, 28, 33, 10, 20] max:min 39 0
epoch:10, iteration:0
0.915481448173523 1.0106459856033325 0.45057767629623413
lambda: 1.022489621392794 0.9944103386023178 0.9831000400048886
epoch:10, iteration:5
0.7470139265060425 1.45162034034729 0.44845348596572876
lambda: 0.9633417627856624 0.9964120088927596 1.0402462283215783
epoch:10, iteration:10
0.8721035122871399 1.4453386068344116 0.5517502427101135
lambda: 0.9685680471327194 0.9608228642688408 1.0706090885984396
epoch:10, iteration:15
0.45129647850990295 1.2913097143173218 0.4886510372161865
lambda: 0.9795432527047631 0.9813639128407526 1.0390928344544843
epoch:10, iteration:20
0.5015329718589783 1.2817622423171997 0.4266473650932312
lambda: 1.0111508512803822 0.9449922732831156 1.0438568754365023
epoch:10, iteration:25
0.6075976490974426 1.2733829021453857 0.4222645163536072
lambda: 0.9263576773853196 1.0139924305139776 1.059649892100703
epoch:10, iteration:30
0.599399983882904 1.0741803646087646 0.41012686491012573
lambda: 1.2439802469060761 0.8453704333269353 0.9106493197669884
epoch:10, iteration:35
1.2582957744598389 0.9232202768325806 0.4480937719345093
lambda: 1.0860401186531905 0.9164189933491217 0.9975408879976876
Epoch Dev:	10
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7537	0.5629	0.5048
Epoch Test:	10
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7500	0.5333	0.4883
whole iter list [20, 37, 18, 38, 7, 24, 22, 0, 28, 13] max:min 39 0
epoch:11, iteration:0
0.42477455735206604 1.0116089582443237 0.45383283495903015
lambda: 1.0735335523644045 0.7759003778097286 1.1505660698258668
epoch:11, iteration:5
0.5719614028930664 0.6849658489227295 0.45495009422302246
lambda: 1.133823131535201 0.9870618730256026 0.8791149954391964
epoch:11, iteration:10
1.0863651037216187 0.8596099615097046 0.4463157653808594
lambda: 0.4728948877893946 1.9440687564121315 0.5830363557984737
epoch:11, iteration:15
0.8861525058746338 1.3345754146575928 0.4504847526550293
lambda: 0.9798655953068476 1.1079900904067983 0.9121443142863542
epoch:11, iteration:20
0.7217063307762146 1.0703729391098022 0.4620012640953064
lambda: 0.9024204071542983 0.9912732091630694 1.106306383682632
epoch:11, iteration:25
0.8638978600502014 1.2154532670974731 0.5629621744155884
lambda: 0.8490720652596132 1.066159481600541 1.0847684531398458
epoch:11, iteration:30
0.7219374775886536 0.9755860567092896 0.4042227268218994
lambda: 1.0015140637676532 1.0324007911666055 0.966085145065741
epoch:11, iteration:35
0.5601471066474915 0.8037900328636169 0.476179838180542
lambda: 0.9634561504289523 0.9132972709580418 1.1232465786130064
Epoch Dev:	11
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7502	0.5611	0.5110
Epoch Test:	11
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7527	0.5387	0.4946
whole iter list [25, 35, 3, 18, 14, 20, 27, 7, 0, 34] max:min 39 0
epoch:12, iteration:0
0.6673218607902527 0.9732635617256165 0.43357837200164795
lambda: 1.2931877211401899 0.8863034188335763 0.820508860026234
epoch:12, iteration:5
0.5455594062805176 0.9890650510787964 0.4205528199672699
lambda: 1.1156641364407887 0.8969312292650473 0.9874046342941639
epoch:12, iteration:10
0.789534866809845 0.6198680996894836 0.43822354078292847
lambda: 1.1360144993567172 1.0415796197584384 0.8224058808848442
epoch:12, iteration:15
0.7726113200187683 1.365522027015686 0.46418195962905884
lambda: 1.113465779458624 1.0740670336111338 0.8124671869302427
epoch:12, iteration:20
0.5439727902412415 0.9594737887382507 0.44497519731521606
lambda: 0.9199187791402776 1.3779355697760318 0.7021456510836904
epoch:12, iteration:25
0.7252364754676819 1.0127664804458618 0.4082488715648651
lambda: 1.0612364162744146 1.0755482194003345 0.8632153643252508
epoch:12, iteration:30
0.4293975830078125 1.183516025543213 0.5151245594024658
lambda: 1.0778359816631684 0.9169081854284443 1.0052558329083872
epoch:12, iteration:35
0.6211496591567993 0.9465019106864929 0.49068284034729004
lambda: 0.9336128894472026 1.0372438779255133 1.0291432326272845
Epoch Dev:	12
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7449	0.5620	0.5022
Epoch Test:	12
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7482	0.5477	0.5081
whole iter list [15, 26, 2, 14, 21, 12, 18, 17, 13, 6] max:min 39 0
epoch:13, iteration:0
0.5799615383148193 0.5891193747520447 0.4455007314682007
lambda: 0.9467582333003678 0.9215656926780851 1.1316760740215472
epoch:13, iteration:5
0.6841428279876709 0.7140511274337769 0.43997544050216675
lambda: 0.9158392333029362 0.9799936743956172 1.1041670923014466
epoch:13, iteration:10
0.4421396851539612 0.7518813610076904 0.42773425579071045
lambda: 1.2066361024826393 0.9187343090174741 0.8746295884998867
epoch:13, iteration:15
0.6981073617935181 1.0172088146209717 0.4543048143386841
lambda: 1.0252539873511501 0.9803219037912988 0.9944241088575514
epoch:13, iteration:20
0.43180525302886963 1.0816527605056763 0.40168094635009766
lambda: 1.0128382566327665 0.9136572885679051 1.0735044547993284
epoch:13, iteration:25
0.7108511924743652 0.9017848968505859 0.36043304204940796
lambda: 0.9002506854491891 0.9385053080709608 1.1612440064798502
epoch:13, iteration:30
0.3621211647987366 0.9522403478622437 0.4127670228481293
lambda: 1.0896259565046051 1.0142629583629488 0.8961110851324461
epoch:13, iteration:35
0.554328441619873 1.0991917848587036 0.43734079599380493
lambda: 1.1055981262012207 0.8078242209919905 1.0865776528067892
Epoch Dev:	13
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7502	0.5620	0.5119
Epoch Test:	13
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7383	0.5315	0.4883
whole iter list [3, 19, 24, 10, 37, 18, 7, 17, 13, 27] max:min 39 0
epoch:14, iteration:0
0.5285385251045227 0.6668775081634521 0.4491696059703827
lambda: 1.0192281593441292 1.0550317344001932 0.9257401062556777
epoch:14, iteration:5
0.46544939279556274 1.0597072839736938 0.4299623966217041
lambda: 0.9061134470797501 1.0248017267133498 1.0690848262069
epoch:14, iteration:10
0.4685932695865631 1.16657292842865 0.39310604333877563
lambda: 1.0216240498454416 1.0375947395456426 0.9407812106089156
epoch:14, iteration:15
0.40872055292129517 1.0041773319244385 0.4876912832260132
lambda: 0.9956217474860676 1.0312742546506808 0.973103997863252
epoch:14, iteration:20
0.35117101669311523 0.83628249168396 0.4123739004135132
lambda: 0.9753787684414742 1.0574854633293373 0.9671357682291881
epoch:14, iteration:25
0.6714415550231934 1.1762124300003052 0.4870494306087494
lambda: 1.0287195661653838 0.8511979384573979 1.1200824953772188
epoch:14, iteration:30
0.6177603602409363 0.7729543447494507 0.45709627866744995
lambda: 0.9839194967342156 0.8192219259041346 1.1968585773616496
epoch:14, iteration:35
0.45929619669914246 0.9807952642440796 0.3513883352279663
lambda: 0.998411478401493 0.9259482821916752 1.0756402394068316
Epoch Dev:	14
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7529	0.5699	0.5136
Epoch Test:	14
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7500	0.5459	0.5000
whole iter list [11, 7, 37, 26, 20, 8, 19, 3, 28, 23] max:min 39 0
epoch:15, iteration:0
0.5249695777893066 0.875443696975708 0.4362295866012573
lambda: 0.953572895884734 1.1511325803570387 0.8952945237582275
epoch:15, iteration:5
0.3815459907054901 1.0013654232025146 0.3432387113571167
lambda: 1.001733972309999 0.9561919669465837 1.0420740607434174
epoch:15, iteration:10
0.48925408720970154 0.9998894333839417 0.42330658435821533
lambda: 0.5958948342823228 1.661067970439672 0.7430371952780052
epoch:15, iteration:15
0.4479494094848633 0.8798630833625793 0.37948960065841675
lambda: 1.0197237742930714 0.9919687528006048 0.9883074729063235
epoch:15, iteration:20
0.6463362574577332 1.2392240762710571 0.36897605657577515
lambda: 1.061490174844462 0.8865345246568009 1.0519753004987373
epoch:15, iteration:25
0.7010214328765869 1.5256617069244385 0.3951563239097595
lambda: 0.7023271976903054 1.3935201131837036 0.9041526891259906
epoch:15, iteration:30
0.76112961769104 0.7340438961982727 0.4190926253795624
lambda: 0.9523848221001104 0.9120662483521419 1.1355489295477477
epoch:15, iteration:35
0.545112133026123 1.1564849615097046 0.4053236246109009
lambda: 1.35005235896011 0.8186039841312818 0.8313436569086083
Epoch Dev:	15
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7599	0.5840	0.5251
Epoch Test:	15
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7545	0.5423	0.4946
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed333/Epoch_15.torchsave
--------------------------------------------------------------------
Training Completed!
Processing...
The best Dev epoch is:  15
The best Dev F1 points for Span Nuclearity Relation are:
 0.7599	0.5840	0.5251
Data path: ./data/pickle-data/depth/to_pt/zh-gcdt-hfl-chinese-roberta-wwm-ext/
Model path: depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed333/
Epoch EvalOnly Test:	15
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7545	0.5423	0.4946
Epoch EvalOnly Test:	15	docid:	0
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7656	0.5167	0.4545
Epoch EvalOnly Test:	15	docid:	1
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7171	0.5349	0.5078
Epoch EvalOnly Test:	15	docid:	2
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7405	0.5253	0.4367
Epoch EvalOnly Test:	15	docid:	3
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7663	0.5272	0.4946
Epoch EvalOnly Test:	15	docid:	4
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7789	0.5842	0.5413
Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
args.use_org_Parseval: True
language embedding name:  hfl/chinese-roberta-wwm-ext
Language embedding loaded from pretrained:  hfl/chinese-roberta-wwm-ext
Checking Data...
 英 语 中 动 态 的 象 似 性 分 析 1 . 导 论 从 广 义 的 角 度 来 看 ， 英 语 中 主 要 分 为 三 个 [UNK] 态 [UNK] ： 主 动 态 ， 中 动 态 和 被 动 态 。 英 语 中 动 态 是 一 种 特 殊 的 语 态 形 式 ， 因 为 它 缺 少 施 事 [ 1 ] 。 从 语 义 的 角 度 来 看 ， 英 语 中 动 态 具 有 如 下 特 点 ： 1 ) 非 事 件 性 ； 2 ) 泛 指 性 ； 3 ) 施 动 性 ； 4 ) 情 态 概 念 [ 2 ] 。 在 主 动 态 的 象 似 性 研 究 中 ， 施 事 的 动 作 产 生 无 论 如 何 先 于 过 程 对 受 事 的 影 响 ， 也 就 是 因 ( 施 事 ) 先 于 果 ( 过 程 对 受 事 的 影 响 ) ， 因 此 ， 主 动 态 是 最 符 合 象 似 性 原 则 的 表 达 。 在 被 动 态 结 构 中 ， 施 事 先 于 受 事 ， 明 显 违 背 了 象 似 性 原 则 。 那 么 ， 就 中 动 态 而 言 ， 它 的 语 法 结 构 是 主 动 态 的 ， 但 是 各 参 与 成 分 之 间 的 关 系 是 被 动 态 的 ， 我 们 如 何 从 象 似 性 角 度 来 分 析 它 呢 ？ 本 文 主 要 探 讨 了 英 语 中 动 态 的 象 似 性 特 点 。 本 文 提 出 的 问 题 如 下 ： ① 英 语 中 动 态 是 如 何 遵 守 或 违 背 象 似 性 原 则 的 ？ ② 英 语 中 动 态 违 背 象 似 性 原 则 的 理 据 为 何 ？ 2 . 象 似 性 原 则 2 . 1 . 顺 序 象 似 性 顺 序 象 似 性 可 以 定 义 为 ： 思 维 的 顺 序 与 语 言 单 位 排 列 的 顺 序 象 似 [ 3 ] 。 green ##berg 也 表 示 ： [UNK] 语 言 成 分 的 顺 序 对 应 与 物 理 现 实 经 验 顺 序 或 知 识 顺 序 [UNK] the order of el ##ement ##s in language pa ##ral ##le ##ls that in ph ##ys ##ical ex ##per ##ience or the order of know ##led ##ge [ 4 ] 。 文 旭 ( 2009 ) 将 这 一 原 则 进 一 步 分 为 两 个 原 则 [ 5 ] ： 1 ) 线 性 序 列 时 间 原 则 ： 连 贯 话 语 中 分 句 的 顺 序 对 应 于 其 所 描 写 的 事 件 发 生 的 时 间 顺 序 。 比 如 [UNK] i cam ##e , i sa ##w , i con ##que ##red . [UNK] 又 比 如 ： max hit harry and harry hit max 表 示 max hit harry 在 先 ， harry hit max 在 后 。 而 max and harry hit ea ##ch other 则 没 有 体 现 出 这 种 时 间 先 后 的 概 念 。 2 ) 线 性 序 列 信 息 原 则 。 该 原 则 主 要 是 与 信 息 的 分 配 相 联 系 。 谈 到 信 息 分 配 ， 我 们 主 要 采 用 的 是 hall ##ida ##y 系 统 功 能 语 言 学 关 于 信 息 分 布 的 观 点 。 hall ##ida ##y & matt ##hi ##ess ##en [ 1 ] 认 为 主 位 ( the ##me ) 是 句 中 信 息 的 起 点 ， 是 整 个 小 句 所 关 注 和 讨 论 的 ， 也 是 小 句 得 以 展 开 的 背 景 。 小 句 中 发 展 主 位 的 部 分 被 称 之 为 述 位 ( r ##he ##me ) 。 通 常 在 陈 述 句 中 非 标 记 性 主 位 ( u ##nm ##ark ##ed the ##me ) 与 主 语 重 合 ， 主 语 以 外 的 任 何 成 分 都 是 标 记 性 主 位 ( mark ##ed the ##me ) [ 1 ] 。 就 信 息 结 构 在 语 言 结 构 中 的 体 现 而 言 ， 非 标 记 式 匹 配 是 ： 与 主 语 重 合 的 非 标 记 性 主 位 传 达 的 是 旧 信 息 ， 而 述 位 传 达 的 是 新 信 息 。 在 语 言 使 用 过 程 中 ， 我 们 会 调 整 主 位 的 实 现 成 分 重 新 分 配 信 息 量 ， 这 样 ， 标 记 性 或 非 象 似 性 表 达 就 产 生 了 。 线 性 序 列 信 息 原 则 表 示 最 熟 悉 的 已 知 背 景 信 息 先 出 现 ， 最 不 熟 悉 的 新 信 息 后 出 现 。 hall ##ida ##y & matt ##hi ##ess ##en [ 1 ] 认 为 主 位 表 达 旧 信 息 ， 述 位 表 达 新 信 息 是 非 标 记 性 信 息 匹 配 结 构 ； 但 是 在 语 言 使 用 中 ， 我 们 可 以 利 用 主 谓 结 构 和 信 息 结 构 [ 的 错 配 ( mi ##sm ##at ##ch ) ] 来 达 到 意 想 不 到 的 修 辞 效 果 。 hall ##ida ##y 也 曾 明 确 表 示 了 象 似 性 的 概 念 ， 他 说 ： 在 语 言 表 达 中 存 在 以 下 规 律 ， 即 信 息 流 沿 着 从 旧 信 息 ( 主 位 ) 流 向 新 信 息 ( 述 位 ) 的 方 向 移 动 ， 这 种 遵 循 时 间 顺 序 的 移 动 象 似 性 地 始 解 了 信 息 流 的 传 播 方 向 ( there is a mo ##ve ##ment from a gi ##ven the ##me ( back ##ground ) to r ##he ##ma ##tic new ( for ##eg ##ro ##und ) ; this mo ##ve ##ment in time con ##st ##ru ##es icon ##ical ##ly the f ##low of information ) [ 6 ] 。 2 . 2 . 距 离 象 似 性 根 据 文 旭 [ 5 ] ， 距 离 象 似 性 定 义 如 下 ： 概 念 间 的 距 离 对 应 于 语 言 成 分 之 间 的 距 离 。 ha ##ima ##n [ 7 ] 认 为 两 个 观 点 在 概 念 的 接 近 必 须 满 足 以 下 四 个 条 件 ： 1 ) 彼 此 享 有 语 义 特 点 或 部 分 ； 2 ) 相 互 影 响 ； 3 ) 在 现 实 中 不 可 分 离 ； 4 ) 不 管 在 现 实 中 可 不 可 以 分 离 ， 均 视 为 一 个 整 体 。 2 . 3 . 数 量 象 似 性 根 据 王 寅 [ 8 ] 数 量 象 似 性 的 定 义 为 ： 语 言 单 位 的 数 量 与 所 表 示 的 概 念 的 量 和 复 杂 程 度 成 正 比 象 似 ， 与 可 预 测 度 成 反 比 。 数 量 象 似 性 的 认 知 基 础 是 ： 语 言 单 位 数 量 一 多 ， 就 会 更 多 地 引 起 人 们 的 注 意 力 ， 心 智 加 工 也 就 更 复 杂 ， 传 递 的 信 息 量 自 然 也 会 更 多 [ 9 ] 。 gi ##vo ##n [ 10 ] 指 出 ， 信 息 处 理 过 程 中 投 入 更 多 的 心 智 努 力 ( men ##tal ef ##fo ##rt ) 需 要 更 多 的 语 言 编 码 材 料 来 表 达 。 语 言 的 每 一 个 单 位 得 以 被 应 用 都 有 它 能 被 使 用 的 价 值 ， 这 个 价 值 就 是 传 递 相 应 的 意 义 ， 因 此 ， 语 言 单 位 越 多 ， 必 定 要 传 递 更 多 的 概 念 。 2 . 4 . 对 称 象 似 性 根 据 ha ##ima ##n [ 7 ] 对 称 象 似 性 指 的 是 语 言 形 式 的 对 称 或 非 对 称 形 式 表 达 了 语 言 形 式 各 部 分 代 表 的 概 念 之 间 存 在 的 对 称 关 系 或 不 对 称 关 系 ( ( a ) s ##ym ##me ##try of form will re ##fl ##ect con ##cept ##ual ( a ) s ##ym ##me ##try ) 。 比 如 sim ##il ##ari ##ty 表 达 的 是 绝 对 对 称 性 概 念 。 harry is sim ##il ##ar to max 与 max is sim ##il ##ar to harry 是 完 全 对 称 的 。 like 表 示 的 不 是 绝 对 对 称 概 念 ， 比 如 max like ##s harry 并 不 与 harry like ##s max 对 称 。 ha ##ima ##n 通 过 多 语 言 对 比 ， 发 现 and 也 可 以 被 用 作 因 果 丛 句 和 条 件 丛 句 。 比 如 ： sam ##my [UNK] s ma ##d and i [UNK] m gl ##ad 和 he come ##s , i will stay 。 在 这 两 句 中 ， su ##mmy [UNK] ma ##d 和 he come ##s 被 看 作 是 表 原 因 的 小 句 。 ha ##ima ##n [ 7 ] 认 为 这 是 一 种 概 念 对 称 的 体 现 ， 因 为 根 据 时 间 的 线 性 特 点 ， 最 先 发 生 的 可 以 看 作 是 背 景 ， 原 因 ， 条 件 。
... ...
That's great! No error found!
All train sample number: 40
Model save path depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/
Finetune from path None
Total trainable parameter number is:  93938722
self.use_org_Parseval:  True
whole iter list [30, 29, 4, 24, 1, 16, 7, 14, 26, 27] max:min 39 0
epoch:1, iteration:0
4.523321628570557 6.093747615814209 1.4980707168579102
epoch:1, iteration:5
4.119343280792236 4.860512733459473 1.4285876750946045
lambda: 1.0440866629120429 0.9699746874427346 0.9859386496452222
epoch:1, iteration:10
3.2517619132995605 4.65289831161499 1.3379478454589844
lambda: 0.916996602313301 1.036236220481757 1.0467671772049423
epoch:1, iteration:15
3.0511715412139893 4.083158493041992 1.3184077739715576
lambda: 0.9658680650200003 0.9307754256354926 1.1033565093445068
epoch:1, iteration:20
3.020078659057617 3.918358325958252 1.2296066284179688
lambda: 0.931279461224226 1.0001221682362982 1.068598370539476
epoch:1, iteration:25
2.4162087440490723 3.431950569152832 1.200439214706421
lambda: 1.0183318325708972 0.9885043651707787 0.993163802258324
epoch:1, iteration:30
1.9559231996536255 3.7153778076171875 1.114269733428955
lambda: 1.1306261424806048 0.9684394539447427 0.9009344035746523
epoch:1, iteration:35
2.1913251876831055 3.595906972885132 1.043500304222107
lambda: 0.9696149378291846 1.0157590232253282 1.0146260389454873
Epoch Dev:	1
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.5682	0.3421	0.2850
Epoch Test:	1
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.5953	0.3399	0.2689
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/Epoch_1.torchsave
whole iter list [11, 4, 10, 15, 8, 38, 14, 34, 17, 5] max:min 39 0
epoch:2, iteration:0
2.35890531539917 3.372471570968628 1.0597548484802246
lambda: 1.0675845741579086 0.9421609873150729 0.9902544385270188
epoch:2, iteration:5
1.9070003032684326 2.838209629058838 1.0237233638763428
lambda: 0.9608299531275327 1.1748182297794734 0.8643518170929941
epoch:2, iteration:10
1.2716827392578125 2.6143932342529297 0.9654315710067749
lambda: 0.9757463519414492 1.015767406869695 1.0084862411888562
epoch:2, iteration:15
1.970922589302063 2.592949628829956 0.9524215459823608
lambda: 0.9910575578472076 0.9888559052705925 1.0200865368821999
epoch:2, iteration:20
1.503421425819397 2.4673590660095215 0.903275728225708
lambda: 0.9155237596039874 1.0565424705804145 1.0279337698155977
epoch:2, iteration:25
1.673527717590332 2.8681507110595703 0.9154772758483887
lambda: 1.0428931347915256 0.9880640926265529 0.9690427725819212
epoch:2, iteration:30
2.1655333042144775 2.789924383163452 0.858589768409729
lambda: 1.040091202047087 0.9466364465285468 1.0132723514243662
epoch:2, iteration:35
1.7453266382217407 2.656008243560791 0.885082483291626
lambda: 0.85589513715165 1.286553771044997 0.8575510918033532
Epoch Dev:	2
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.6209	0.3931	0.3588
Epoch Test:	2
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.6466	0.4137	0.3507
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/Epoch_2.torchsave
whole iter list [2, 7, 1, 22, 28, 27, 34, 29, 17, 36] max:min 39 0
epoch:3, iteration:0
2.074693202972412 2.4520442485809326 0.885490894317627
lambda: 0.9491517445699307 0.9296597386109539 1.1211885168191156
epoch:3, iteration:5
1.7628740072250366 2.400419235229492 0.7875978350639343
lambda: 1.1807338875675875 0.7686264035635858 1.0506397088688266
epoch:3, iteration:10
1.4701907634735107 2.2556629180908203 0.8261659145355225
lambda: 0.9669382987804191 1.0466360728850936 0.9864256283344871
epoch:3, iteration:15
1.393458604812622 2.2509348392486572 0.734266996383667
lambda: 1.192574811420537 0.8125163986663958 0.9949087899130676
epoch:3, iteration:20
1.4225952625274658 1.960065245628357 0.7875188589096069
lambda: 0.9101789590050274 1.0742008246630426 1.0156202163319303
epoch:3, iteration:25
1.1616395711898804 2.094848394393921 0.8313900828361511
lambda: 0.9118114990849956 1.042869300939773 1.0453191999752314
epoch:3, iteration:30
1.2097595930099487 2.207361936569214 0.728272557258606
lambda: 1.017968236230208 0.9736197276557023 1.0084120361140891
epoch:3, iteration:35
1.1916923522949219 2.0012729167938232 0.7476454973220825
lambda: 1.0991550224515003 0.8470267919292576 1.0538181856192421
Epoch Dev:	3
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.6966	0.4785	0.4345
Epoch Test:	3
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.6799	0.4478	0.3894
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/Epoch_3.torchsave
whole iter list [39, 21, 3, 10, 31, 26, 33, 16, 9, 24] max:min 39 0
epoch:4, iteration:0
1.194731593132019 1.687035083770752 0.6735470294952393
lambda: 0.932455878132481 1.0053754728415183 1.0621686490260005
epoch:4, iteration:5
1.2948328256607056 1.7319098711013794 0.6696715354919434
lambda: 1.0124787200384837 0.9976403421349795 0.9898809378265366
epoch:4, iteration:10
1.378156065940857 0.9607335329055786 0.6299677491188049
lambda: 0.8549315316989585 1.0465678252464625 1.098500643054579
epoch:4, iteration:15
1.5149192810058594 1.6522468328475952 0.6933647394180298
lambda: 1.20869601837788 0.9159206732000702 0.87538330842205
epoch:4, iteration:20
1.047743797302246 2.018893003463745 0.702478289604187
lambda: 0.9773163525365608 0.8661983282450312 1.156485319218408
epoch:4, iteration:25
1.2415558099746704 1.7964260578155518 0.7013784646987915
lambda: 1.0897541272975777 0.8688977068824939 1.0413481658199284
epoch:4, iteration:30
1.906156301498413 1.5266327857971191 0.6554057598114014
lambda: 0.9957877918431411 0.9506131841304865 1.0535990240263724
epoch:4, iteration:35
1.6024818420410156 2.0452818870544434 0.6345799565315247
lambda: 1.2057480650242807 0.9502837921756279 0.8439681428000916
Epoch Dev:	4
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7212	0.5040	0.4609
Epoch Test:	4
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7032	0.4946	0.4317
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/Epoch_4.torchsave
whole iter list [17, 34, 11, 3, 27, 22, 30, 4, 9, 31] max:min 39 0
epoch:5, iteration:0
0.9361727237701416 1.7977045774459839 0.6958494186401367
lambda: 0.958170036985177 1.034935229372509 1.006894733642314
epoch:5, iteration:5
1.3309760093688965 2.5225417613983154 0.6599738597869873
lambda: 0.9733842089807114 1.1652722367969557 0.861343554222333
epoch:5, iteration:10
0.9854269623756409 1.6915035247802734 0.6409345865249634
lambda: 0.8400411473934697 1.1512372373312307 1.0087216152752996
epoch:5, iteration:15
1.2452200651168823 1.8330411911010742 0.6668552160263062
lambda: 0.9366062706844813 1.034373248734552 1.0290204805809664
epoch:5, iteration:20
0.9828351736068726 1.5273576974868774 0.6397708058357239
lambda: 1.0996511077765907 0.8818269151607868 1.018521977062622
epoch:5, iteration:25
0.9297823905944824 1.6228073835372925 0.5973482131958008
lambda: 1.0971757693602475 0.9256380093041107 0.9771862213356419
epoch:5, iteration:30
0.8752186298370361 1.559808611869812 0.6881951093673706
lambda: 0.9605733196570975 1.0588363400320224 0.98059034031088
epoch:5, iteration:35
1.5696039199829102 1.7326931953430176 0.6104936003684998
lambda: 1.0196219699261335 0.9344682282090762 1.0459098018647903
Epoch Dev:	5
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7318	0.5224	0.4741
Epoch Test:	5
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7086	0.4910	0.4379
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/Epoch_5.torchsave
whole iter list [27, 15, 29, 22, 20, 1, 11, 36, 9, 23] max:min 39 0
epoch:6, iteration:0
0.945252001285553 1.523038387298584 0.5726247429847717
lambda: 0.8994397954574224 1.070177744818052 1.0303824597245255
epoch:6, iteration:5
0.856618344783783 1.5695823431015015 0.5535901188850403
lambda: 0.9497127876744124 0.931305827587333 1.1189813847382546
epoch:6, iteration:10
0.77407306432724 1.090486764907837 0.6306020021438599
lambda: 0.7901401209625034 1.1116838346730424 1.0981760443644542
epoch:6, iteration:15
0.8704719543457031 1.4955918788909912 0.5454433560371399
lambda: 1.0980442428486232 0.8484633713776083 1.0534923857737684
epoch:6, iteration:20
0.7990423440933228 1.9116429090499878 0.5352785587310791
lambda: 0.9046531669593763 1.0088160539687934 1.0865307790718304
epoch:6, iteration:25
1.187006950378418 1.6903473138809204 0.68129962682724
lambda: 0.8629503626977146 1.1782400281891456 0.9588096091131395
epoch:6, iteration:30
0.7420853972434998 1.1922788619995117 0.5757548809051514
lambda: 0.9411820797440256 0.976505699188824 1.0823122210671503
epoch:6, iteration:35
1.0132182836532593 1.2784736156463623 0.49030375480651855
lambda: 0.9605055653450072 0.9887152176193383 1.0507792170356547
Epoch Dev:	6
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7274	0.5295	0.4890
Epoch Test:	6
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7086	0.5027	0.4640
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/Epoch_6.torchsave
whole iter list [22, 14, 13, 34, 28, 20, 31, 27, 29, 24] max:min 39 0
epoch:7, iteration:0
1.392991304397583 2.0321450233459473 0.5854700803756714
lambda: 0.6720329517824545 1.6604387418099014 0.6675283064076442
epoch:7, iteration:5
0.8076814413070679 1.3345718383789062 0.547379732131958
lambda: 1.161278715755964 0.7811229709363057 1.0575983133077307
epoch:7, iteration:10
0.8631601333618164 1.020234227180481 0.5434707403182983
lambda: 1.039051813222657 0.9956602979646931 0.9652878888126497
epoch:7, iteration:15
0.8612201809883118 1.4188990592956543 0.5724095106124878
lambda: 1.0771597757670792 1.0693554173407738 0.8534848068921473
epoch:7, iteration:20
0.6909655332565308 1.3472745418548584 0.6231896877288818
lambda: 0.9803380231792977 1.094878749008335 0.9247832278123671
epoch:7, iteration:25
0.8018692135810852 1.1742234230041504 0.47872403264045715
lambda: 0.9222214243731013 1.1003287795855523 0.9774497960413461
epoch:7, iteration:30
0.8188366293907166 1.4183071851730347 0.6231412887573242
lambda: 0.9972038182655394 1.0026682704609358 1.0001279112735248
epoch:7, iteration:35
0.9671621322631836 1.589257001876831 0.6094106435775757
lambda: 0.9274537468752497 1.073914402365689 0.9986318507590612
Epoch Dev:	7
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7361	0.5268	0.4793
Epoch Test:	7
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7221	0.5000	0.4559
whole iter list [37, 22, 8, 36, 9, 12, 14, 6, 17, 24] max:min 39 0
epoch:8, iteration:0
0.701161801815033 1.298174500465393 0.5426576733589172
lambda: 1.1120131298318403 0.7988835097496283 1.0891033604185314
epoch:8, iteration:5
0.8210768699645996 1.1053764820098877 0.5232338905334473
lambda: 1.492026548220897 0.7174707116651724 0.7905027401139307
epoch:8, iteration:10
0.8586294054985046 1.202321171760559 0.5023757815361023
lambda: 1.0796506814229434 0.899791482662372 1.0205578359146847
epoch:8, iteration:15
0.539191722869873 1.4765093326568604 0.5619126558303833
lambda: 1.0404698925690032 0.9817535683786595 0.9777765390523373
epoch:8, iteration:20
0.9909424185752869 1.6924893856048584 0.4679240882396698
lambda: 0.9326726210818268 1.2714000283851277 0.7959273505330458
epoch:8, iteration:25
1.0254453420639038 0.4617060720920563 0.437287837266922
lambda: 0.9395915582266522 0.997751429585619 1.0626570121877292
epoch:8, iteration:30
0.6011074185371399 1.2819318771362305 0.466105580329895
lambda: 0.9749349619528777 0.951252427283644 1.0738126107634778
epoch:8, iteration:35
0.6634134650230408 1.3195760250091553 0.5143393874168396
lambda: 0.9316221988872186 1.280372125666609 0.7880056754461727
Epoch Dev:	8
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7414	0.5453	0.4987
Epoch Test:	8
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7167	0.4964	0.4568
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/Epoch_8.torchsave
whole iter list [5, 33, 13, 2, 25, 36, 20, 4, 38, 11] max:min 39 0
epoch:9, iteration:0
0.7965058088302612 1.2962591648101807 0.46933454275131226
lambda: 0.9440925985683696 1.0450423235162971 1.0108650779153334
epoch:9, iteration:5
0.6226845383644104 1.0829583406448364 0.4521690607070923
lambda: 1.0351525707824103 0.9591413929524282 1.0057060362651615
epoch:9, iteration:10
0.622884213924408 1.199262261390686 0.5078774094581604
lambda: 1.0127174439787057 0.9608977914111088 1.0263847646101858
epoch:9, iteration:15
0.7555878758430481 0.3041619658470154 0.4286004900932312
lambda: 1.0213782389285473 1.0289742761231995 0.949647484948253
epoch:9, iteration:20
1.047377109527588 1.8051843643188477 0.5078903436660767
lambda: 1.0192079725297762 0.8945426205105588 1.0862494069596649
epoch:9, iteration:25
0.8508330583572388 1.359990119934082 0.5642329454421997
lambda: 0.9946277465882161 1.2784279014107156 0.7269443520010685
epoch:9, iteration:30
0.9936052560806274 1.5624452829360962 0.4269132614135742
lambda: 0.958844644250776 1.0076633619946238 1.0334919937546003
epoch:9, iteration:35
0.8241963386535645 0.7166924476623535 0.4745006561279297
lambda: 1.0740505609214606 1.089534595260591 0.8364148438179485
Epoch Dev:	9
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7423	0.5558	0.5031
Epoch Test:	9
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7356	0.5351	0.4937
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/Epoch_9.torchsave
whole iter list [38, 19, 27, 26, 21, 16, 2, 23, 24, 9] max:min 39 0
epoch:10, iteration:0
0.6008008718490601 1.2003650665283203 0.4345366358757019
lambda: 1.078719568734043 0.9649863146496589 0.9562941166162984
epoch:10, iteration:5
0.7504818439483643 1.2265347242355347 0.5162110328674316
lambda: 1.0073772980744036 0.921634225003864 1.0709884769217328
epoch:10, iteration:10
0.525761604309082 1.147116780281067 0.47039586305618286
lambda: 1.387640820517975 0.8418874749419979 0.7704717045400272
epoch:10, iteration:15
0.7178474068641663 1.0827181339263916 0.49821269512176514
lambda: 0.9989681557915371 0.90094983011701 1.100082014091453
epoch:10, iteration:20
0.8707708716392517 1.5454927682876587 0.4299617409706116
lambda: 1.0910130614629763 0.8518349767452084 1.057151961791816
epoch:10, iteration:25
0.2875113785266876 0.996005117893219 0.4911966025829315
lambda: 1.0343321000296724 0.9268435433188777 1.03882435665145
epoch:10, iteration:30
0.5551180839538574 1.0865651369094849 0.5153710842132568
lambda: 1.3485889140151364 0.6904099562923658 0.9610011296924983
epoch:10, iteration:35
0.8676373362541199 0.8740695714950562 0.4811299443244934
lambda: 0.9198866266271226 0.9571104761775264 1.1230028971953505
Epoch Dev:	10
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7555	0.5646	0.5172
Epoch Test:	10
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7320	0.5216	0.4793
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/Epoch_10.torchsave
whole iter list [15, 25, 13, 4, 38, 7, 23, 9, 34, 33] max:min 39 0
epoch:11, iteration:0
0.6918694972991943 0.6633669137954712 0.4539988040924072
lambda: 1.0352434533903234 0.9903211265718934 0.9744354200377828
epoch:11, iteration:5
0.9417898058891296 1.3115832805633545 0.4050252437591553
lambda: 1.0436323401247132 0.9465893041925114 1.009778355682775
epoch:11, iteration:10
0.58735591173172 1.1008950471878052 0.4462719261646271
lambda: 0.9448817096242772 0.9449427805312073 1.1101755098445154
epoch:11, iteration:15
0.3655965030193329 1.047577977180481 0.46221810579299927
lambda: 1.1602152827837755 0.8872113196255665 0.9525733975906581
epoch:11, iteration:20
0.757071316242218 1.0645582675933838 0.43381714820861816
lambda: 0.9969724835806845 0.9814759804298251 1.0215515359894907
epoch:11, iteration:25
0.651087760925293 1.0294561386108398 0.41145721077919006
lambda: 0.9276070723370196 1.0493519390846962 1.0230409885782843
epoch:11, iteration:30
0.6753036379814148 1.1854205131530762 0.536120593547821
lambda: 0.818966467581123 1.2235172828832368 0.9575162495356401
epoch:11, iteration:35
0.6632031202316284 1.2492225170135498 0.407922625541687
lambda: 1.2001179085721156 0.9577524298341473 0.8421296615937371
Epoch Dev:	11
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7476	0.5620	0.5242
Epoch Test:	11
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7428	0.5396	0.4955
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/Epoch_11.torchsave
whole iter list [14, 22, 9, 23, 38, 16, 31, 6, 24, 8] max:min 39 0
epoch:12, iteration:0
0.9334454536437988 0.970582902431488 0.3892625570297241
lambda: 1.0838542791740642 0.8317581761032914 1.0843875447226445
epoch:12, iteration:5
0.3843728005886078 1.1596224308013916 0.4786667227745056
lambda: 1.024777440741681 0.9730267505573064 1.0021958087010123
epoch:12, iteration:10
0.6728624105453491 1.042676568031311 0.39026981592178345
lambda: 0.8806130535363672 1.256490046274717 0.8628969001889158
epoch:12, iteration:15
0.4850687086582184 0.6820871233940125 0.4584975838661194
lambda: 0.94336395738623 1.1047849290691907 0.9518511135445794
epoch:12, iteration:20
0.4506825804710388 1.1218669414520264 0.3733604848384857
lambda: 0.6880759887837781 1.5974782811962016 0.7144457300200203
epoch:12, iteration:25
0.42696821689605713 0.7759579420089722 0.42195677757263184
lambda: 1.1170269695985606 0.8309810097343651 1.0519920206670743
epoch:12, iteration:30
0.8153584599494934 0.7556737661361694 0.401130348443985
lambda: 0.9338516954152327 1.2451910020227133 0.8209573025620541
epoch:12, iteration:35
0.5884942412376404 0.5759676098823547 0.418703556060791
lambda: 0.9790056679759844 1.0349796325511689 0.9860146994728467
Epoch Dev:	12
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7529	0.5699	0.5233
Epoch Test:	12
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7401	0.5360	0.4991
whole iter list [30, 28, 0, 16, 6, 4, 3, 18, 11, 1] max:min 39 0
epoch:13, iteration:0
0.3134301006793976 0.9029784798622131 0.4219767153263092
lambda: 1.1134704702591158 0.9312707837436878 0.9552587459971963
epoch:13, iteration:5
0.49547135829925537 1.050354242324829 0.3730524182319641
lambda: 1.2805419560700197 0.8480726821046247 0.8713853618253552
epoch:13, iteration:10
0.41419586539268494 0.9894317388534546 0.359028160572052
lambda: 0.8936641779393154 1.1613198031161316 0.9450160189445532
epoch:13, iteration:15
0.3347027003765106 0.9733257293701172 0.4066818356513977
lambda: 1.081518829828681 1.0658173958783965 0.8526637742929222
epoch:13, iteration:20
0.6299669742584229 1.3224091529846191 0.35056793689727783
lambda: 0.8533562485212953 1.0288035924906407 1.117840158988064
epoch:13, iteration:25
0.5731296539306641 0.8364443182945251 0.4711403548717499
lambda: 1.016432885508265 0.9485709579322181 1.034996156559517
epoch:13, iteration:30
0.48788022994995117 0.75037682056427 0.34740495681762695
lambda: 0.983040023281529 1.1124315984451154 0.9045283782733557
epoch:13, iteration:35
0.8983251452445984 1.636033296585083 0.4519248306751251
lambda: 0.8494248222695973 1.084819883001631 1.0657552947287716
Epoch Dev:	13
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7564	0.5761	0.5268
Epoch Test:	13
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7437	0.5396	0.4982
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/Epoch_13.torchsave
whole iter list [9, 3, 23, 32, 35, 16, 21, 15, 13, 27] max:min 39 0
epoch:14, iteration:0
1.002236247062683 0.7947842478752136 0.38367995619773865
lambda: 0.9170356663552881 0.9254949304321244 1.1574694032125874
epoch:14, iteration:5
0.44744691252708435 0.9422580599784851 0.45349109172821045
lambda: 0.9732171505784006 0.9816540321751837 1.045128817246416
epoch:14, iteration:10
0.7680105566978455 1.2264058589935303 0.4232332408428192
lambda: 0.977363544115009 1.1183897364139987 0.904246719470992
epoch:14, iteration:15
0.6968168020248413 1.068869709968567 0.5299919843673706
lambda: 1.0107131407897667 0.900830911455272 1.0884559477549614
epoch:14, iteration:20
0.5965219736099243 0.7969744205474854 0.3912509083747864
lambda: 1.0021991385414046 0.9843103187718849 1.0134905426867105
epoch:14, iteration:25
0.459318071603775 0.628120481967926 0.35967278480529785
lambda: 1.1863740922025958 0.7762494615529059 1.0373764462444983
epoch:14, iteration:30
0.5444259643554688 0.8244098424911499 0.3772719204425812
lambda: 0.8456068833544494 1.0465080426553883 1.107885073990162
epoch:14, iteration:35
0.3243597149848938 0.8557865023612976 0.4962066411972046
lambda: 1.2696971657751794 0.747785405183018 0.9825174290418028
Epoch Dev:	14
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7643	0.5690	0.5242
Epoch Test:	14
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7563	0.5441	0.5036
whole iter list [22, 35, 34, 18, 19, 4, 24, 33, 32, 8] max:min 39 0
epoch:15, iteration:0
0.9663143754005432 1.58012056350708 0.4288783669471741
lambda: 0.919599269726553 0.9844605149762482 1.0959402152971984
epoch:15, iteration:5
0.5037807822227478 1.0614696741104126 0.35191065073013306
lambda: 0.8776134791594276 0.9665227715669459 1.1558637492736268
epoch:15, iteration:10
0.6173521280288696 0.7122985124588013 0.37946388125419617
lambda: 0.9242718648243426 1.0721993972352606 1.0035287379403965
epoch:15, iteration:15
0.49754202365875244 0.6395646929740906 0.35540634393692017
lambda: 0.9878124485752364 1.009200570409518 1.0029869810152456
epoch:15, iteration:20
0.3949466049671173 0.723079264163971 0.43844977021217346
lambda: 1.1258826923986907 0.7909567940692435 1.0831605135320657
epoch:15, iteration:25
0.5042767524719238 0.8844178318977356 0.3600844442844391
lambda: 1.1706465739029053 0.9181845030925522 0.9111689230045421
epoch:15, iteration:30
0.34286683797836304 0.715238630771637 0.3963988423347473
lambda: 0.9857294212128043 0.9932723906666754 1.0209981881205201
epoch:15, iteration:35
0.3852154612541199 0.8857972621917725 0.31105148792266846
lambda: 0.9916943559303765 1.0681605101373612 0.9401451339322623
Epoch Dev:	15
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7652	0.5796	0.5330
Epoch Test:	15
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7509	0.5531	0.5054
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/Epoch_15.torchsave
--------------------------------------------------------------------
Training Completed!
Processing...
The best Dev epoch is:  15
The best Dev F1 points for Span Nuclearity Relation are:
 0.7652	0.5796	0.5330
Data path: ./data/pickle-data/depth/to_pt/zh-gcdt-hfl-chinese-roberta-wwm-ext/
Model path: depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed444/
Epoch EvalOnly Test:	15
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7509	0.5531	0.5054
Epoch EvalOnly Test:	15	docid:	0
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7560	0.5120	0.4641
Epoch EvalOnly Test:	15	docid:	1
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7093	0.5388	0.5039
Epoch EvalOnly Test:	15	docid:	2
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7532	0.5633	0.4684
Epoch EvalOnly Test:	15	docid:	3
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7935	0.5707	0.5109
Epoch EvalOnly Test:	15	docid:	4
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7558	0.5776	0.5512
Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
args.use_org_Parseval: True
language embedding name:  hfl/chinese-roberta-wwm-ext
Language embedding loaded from pretrained:  hfl/chinese-roberta-wwm-ext
Checking Data...
 英 语 中 动 态 的 象 似 性 分 析 1 . 导 论 从 广 义 的 角 度 来 看 ， 英 语 中 主 要 分 为 三 个 [UNK] 态 [UNK] ： 主 动 态 ， 中 动 态 和 被 动 态 。 英 语 中 动 态 是 一 种 特 殊 的 语 态 形 式 ， 因 为 它 缺 少 施 事 [ 1 ] 。 从 语 义 的 角 度 来 看 ， 英 语 中 动 态 具 有 如 下 特 点 ： 1 ) 非 事 件 性 ； 2 ) 泛 指 性 ； 3 ) 施 动 性 ； 4 ) 情 态 概 念 [ 2 ] 。 在 主 动 态 的 象 似 性 研 究 中 ， 施 事 的 动 作 产 生 无 论 如 何 先 于 过 程 对 受 事 的 影 响 ， 也 就 是 因 ( 施 事 ) 先 于 果 ( 过 程 对 受 事 的 影 响 ) ， 因 此 ， 主 动 态 是 最 符 合 象 似 性 原 则 的 表 达 。 在 被 动 态 结 构 中 ， 施 事 先 于 受 事 ， 明 显 违 背 了 象 似 性 原 则 。 那 么 ， 就 中 动 态 而 言 ， 它 的 语 法 结 构 是 主 动 态 的 ， 但 是 各 参 与 成 分 之 间 的 关 系 是 被 动 态 的 ， 我 们 如 何 从 象 似 性 角 度 来 分 析 它 呢 ？ 本 文 主 要 探 讨 了 英 语 中 动 态 的 象 似 性 特 点 。 本 文 提 出 的 问 题 如 下 ： ① 英 语 中 动 态 是 如 何 遵 守 或 违 背 象 似 性 原 则 的 ？ ② 英 语 中 动 态 违 背 象 似 性 原 则 的 理 据 为 何 ？ 2 . 象 似 性 原 则 2 . 1 . 顺 序 象 似 性 顺 序 象 似 性 可 以 定 义 为 ： 思 维 的 顺 序 与 语 言 单 位 排 列 的 顺 序 象 似 [ 3 ] 。 green ##berg 也 表 示 ： [UNK] 语 言 成 分 的 顺 序 对 应 与 物 理 现 实 经 验 顺 序 或 知 识 顺 序 [UNK] the order of el ##ement ##s in language pa ##ral ##le ##ls that in ph ##ys ##ical ex ##per ##ience or the order of know ##led ##ge [ 4 ] 。 文 旭 ( 2009 ) 将 这 一 原 则 进 一 步 分 为 两 个 原 则 [ 5 ] ： 1 ) 线 性 序 列 时 间 原 则 ： 连 贯 话 语 中 分 句 的 顺 序 对 应 于 其 所 描 写 的 事 件 发 生 的 时 间 顺 序 。 比 如 [UNK] i cam ##e , i sa ##w , i con ##que ##red . [UNK] 又 比 如 ： max hit harry and harry hit max 表 示 max hit harry 在 先 ， harry hit max 在 后 。 而 max and harry hit ea ##ch other 则 没 有 体 现 出 这 种 时 间 先 后 的 概 念 。 2 ) 线 性 序 列 信 息 原 则 。 该 原 则 主 要 是 与 信 息 的 分 配 相 联 系 。 谈 到 信 息 分 配 ， 我 们 主 要 采 用 的 是 hall ##ida ##y 系 统 功 能 语 言 学 关 于 信 息 分 布 的 观 点 。 hall ##ida ##y & matt ##hi ##ess ##en [ 1 ] 认 为 主 位 ( the ##me ) 是 句 中 信 息 的 起 点 ， 是 整 个 小 句 所 关 注 和 讨 论 的 ， 也 是 小 句 得 以 展 开 的 背 景 。 小 句 中 发 展 主 位 的 部 分 被 称 之 为 述 位 ( r ##he ##me ) 。 通 常 在 陈 述 句 中 非 标 记 性 主 位 ( u ##nm ##ark ##ed the ##me ) 与 主 语 重 合 ， 主 语 以 外 的 任 何 成 分 都 是 标 记 性 主 位 ( mark ##ed the ##me ) [ 1 ] 。 就 信 息 结 构 在 语 言 结 构 中 的 体 现 而 言 ， 非 标 记 式 匹 配 是 ： 与 主 语 重 合 的 非 标 记 性 主 位 传 达 的 是 旧 信 息 ， 而 述 位 传 达 的 是 新 信 息 。 在 语 言 使 用 过 程 中 ， 我 们 会 调 整 主 位 的 实 现 成 分 重 新 分 配 信 息 量 ， 这 样 ， 标 记 性 或 非 象 似 性 表 达 就 产 生 了 。 线 性 序 列 信 息 原 则 表 示 最 熟 悉 的 已 知 背 景 信 息 先 出 现 ， 最 不 熟 悉 的 新 信 息 后 出 现 。 hall ##ida ##y & matt ##hi ##ess ##en [ 1 ] 认 为 主 位 表 达 旧 信 息 ， 述 位 表 达 新 信 息 是 非 标 记 性 信 息 匹 配 结 构 ； 但 是 在 语 言 使 用 中 ， 我 们 可 以 利 用 主 谓 结 构 和 信 息 结 构 [ 的 错 配 ( mi ##sm ##at ##ch ) ] 来 达 到 意 想 不 到 的 修 辞 效 果 。 hall ##ida ##y 也 曾 明 确 表 示 了 象 似 性 的 概 念 ， 他 说 ： 在 语 言 表 达 中 存 在 以 下 规 律 ， 即 信 息 流 沿 着 从 旧 信 息 ( 主 位 ) 流 向 新 信 息 ( 述 位 ) 的 方 向 移 动 ， 这 种 遵 循 时 间 顺 序 的 移 动 象 似 性 地 始 解 了 信 息 流 的 传 播 方 向 ( there is a mo ##ve ##ment from a gi ##ven the ##me ( back ##ground ) to r ##he ##ma ##tic new ( for ##eg ##ro ##und ) ; this mo ##ve ##ment in time con ##st ##ru ##es icon ##ical ##ly the f ##low of information ) [ 6 ] 。 2 . 2 . 距 离 象 似 性 根 据 文 旭 [ 5 ] ， 距 离 象 似 性 定 义 如 下 ： 概 念 间 的 距 离 对 应 于 语 言 成 分 之 间 的 距 离 。 ha ##ima ##n [ 7 ] 认 为 两 个 观 点 在 概 念 的 接 近 必 须 满 足 以 下 四 个 条 件 ： 1 ) 彼 此 享 有 语 义 特 点 或 部 分 ； 2 ) 相 互 影 响 ； 3 ) 在 现 实 中 不 可 分 离 ； 4 ) 不 管 在 现 实 中 可 不 可 以 分 离 ， 均 视 为 一 个 整 体 。 2 . 3 . 数 量 象 似 性 根 据 王 寅 [ 8 ] 数 量 象 似 性 的 定 义 为 ： 语 言 单 位 的 数 量 与 所 表 示 的 概 念 的 量 和 复 杂 程 度 成 正 比 象 似 ， 与 可 预 测 度 成 反 比 。 数 量 象 似 性 的 认 知 基 础 是 ： 语 言 单 位 数 量 一 多 ， 就 会 更 多 地 引 起 人 们 的 注 意 力 ， 心 智 加 工 也 就 更 复 杂 ， 传 递 的 信 息 量 自 然 也 会 更 多 [ 9 ] 。 gi ##vo ##n [ 10 ] 指 出 ， 信 息 处 理 过 程 中 投 入 更 多 的 心 智 努 力 ( men ##tal ef ##fo ##rt ) 需 要 更 多 的 语 言 编 码 材 料 来 表 达 。 语 言 的 每 一 个 单 位 得 以 被 应 用 都 有 它 能 被 使 用 的 价 值 ， 这 个 价 值 就 是 传 递 相 应 的 意 义 ， 因 此 ， 语 言 单 位 越 多 ， 必 定 要 传 递 更 多 的 概 念 。 2 . 4 . 对 称 象 似 性 根 据 ha ##ima ##n [ 7 ] 对 称 象 似 性 指 的 是 语 言 形 式 的 对 称 或 非 对 称 形 式 表 达 了 语 言 形 式 各 部 分 代 表 的 概 念 之 间 存 在 的 对 称 关 系 或 不 对 称 关 系 ( ( a ) s ##ym ##me ##try of form will re ##fl ##ect con ##cept ##ual ( a ) s ##ym ##me ##try ) 。 比 如 sim ##il ##ari ##ty 表 达 的 是 绝 对 对 称 性 概 念 。 harry is sim ##il ##ar to max 与 max is sim ##il ##ar to harry 是 完 全 对 称 的 。 like 表 示 的 不 是 绝 对 对 称 概 念 ， 比 如 max like ##s harry 并 不 与 harry like ##s max 对 称 。 ha ##ima ##n 通 过 多 语 言 对 比 ， 发 现 and 也 可 以 被 用 作 因 果 丛 句 和 条 件 丛 句 。 比 如 ： sam ##my [UNK] s ma ##d and i [UNK] m gl ##ad 和 he come ##s , i will stay 。 在 这 两 句 中 ， su ##mmy [UNK] ma ##d 和 he come ##s 被 看 作 是 表 原 因 的 小 句 。 ha ##ima ##n [ 7 ] 认 为 这 是 一 种 概 念 对 称 的 体 现 ， 因 为 根 据 时 间 的 线 性 特 点 ， 最 先 发 生 的 可 以 看 作 是 背 景 ， 原 因 ， 条 件 。
... ...
That's great! No error found!
All train sample number: 40
Model save path depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/
Finetune from path None
Total trainable parameter number is:  93938722
self.use_org_Parseval:  True
whole iter list [37, 25, 2, 36, 23, 7, 21, 13, 28, 11] max:min 39 0
epoch:1, iteration:0
4.6396050453186035 6.831132888793945 1.8182271718978882
epoch:1, iteration:5
3.3269708156585693 4.351353168487549 1.5912959575653076
lambda: 0.9445570899956485 1.0426612591258226 1.012781650878529
epoch:1, iteration:10
2.706913471221924 4.598242282867432 1.499320149421692
lambda: 1.1078121055534824 0.9901900721877466 0.9019978222587713
epoch:1, iteration:15
2.836531400680542 4.1771464347839355 1.3465149402618408
lambda: 0.9537539782522392 1.0270677776396573 1.0191782441081036
epoch:1, iteration:20
2.759521245956421 3.956672430038452 1.3655178546905518
lambda: 1.025061629056843 0.9482396254735856 1.0266987454695715
epoch:1, iteration:25
2.4722869396209717 3.811833620071411 1.2648489475250244
lambda: 1.1115659604450383 0.9298530359279198 0.9585810036270419
epoch:1, iteration:30
2.2097220420837402 4.140859603881836 1.1671693325042725
lambda: 1.1309093606475924 0.8873878225961862 0.9817028167562215
epoch:1, iteration:35
1.7074031829833984 2.9028513431549072 1.1002224683761597
lambda: 0.8616861493227471 1.1387677195388806 0.9995461311383722
Epoch Dev:	1
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.5699	0.3175	0.2823
Epoch Test:	1
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.5737	0.3201	0.2698
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/Epoch_1.torchsave
whole iter list [22, 27, 28, 12, 23, 39, 34, 5, 11, 4] max:min 39 0
epoch:2, iteration:0
2.304903984069824 4.037272930145264 1.0910847187042236
lambda: 1.0260835458161794 0.9611448114180048 1.0127716427658158
epoch:2, iteration:5
2.1450469493865967 2.4458084106445312 1.0336613655090332
lambda: 1.3203770527193277 0.8729943743789825 0.8066285729016897
epoch:2, iteration:10
2.0362274646759033 2.336771249771118 1.1033798456192017
lambda: 1.042907638560245 0.9880679896771828 0.9690243717625722
epoch:2, iteration:15
1.9969217777252197 3.2122514247894287 0.9560940265655518
lambda: 1.0297974132090193 1.0066096636802173 0.9635929231107636
epoch:2, iteration:20
1.4464210271835327 2.5454041957855225 1.0469989776611328
lambda: 1.0815415113737987 0.9417578222237664 0.9767006664024348
epoch:2, iteration:25
2.1871585845947266 3.10323166847229 0.9906728267669678
lambda: 0.9190110889844102 1.039869303067639 1.041119607947951
epoch:2, iteration:30
1.9157578945159912 2.809415817260742 0.8940127491950989
lambda: 0.988158529602082 1.061671773655646 0.9501696967422721
epoch:2, iteration:35
2.039489269256592 2.5453500747680664 0.9048891067504883
lambda: 1.0177325361220222 1.0663559240904676 0.9159115397875104
Epoch Dev:	2
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.6324	0.4230	0.3738
Epoch Test:	2
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.6313	0.3903	0.3264
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/Epoch_2.torchsave
whole iter list [32, 24, 28, 22, 29, 6, 16, 9, 20, 1] max:min 39 0
epoch:3, iteration:0
2.054621696472168 2.5652573108673096 0.8589702844619751
lambda: 1.0006246210857141 1.031485945798239 0.9678894331160465
epoch:3, iteration:5
1.7748109102249146 2.543178081512451 0.8815971612930298
lambda: 1.0079840654163834 0.864958827190081 1.1270571073935352
epoch:3, iteration:10
1.4560508728027344 1.7852789163589478 0.9180344343185425
lambda: 1.0083205078553719 1.0447423659615964 0.9469371261830316
epoch:3, iteration:15
1.4662882089614868 1.9880433082580566 0.8466439247131348
lambda: 0.940103757253909 0.9918853970970849 1.0680108456490065
epoch:3, iteration:20
1.545460820198059 2.311340093612671 0.8729925155639648
lambda: 1.0494482615398457 0.8491689002855326 1.101382838174622
epoch:3, iteration:25
1.5020134449005127 2.1373486518859863 0.7483627796173096
lambda: 1.0699997625523956 0.9428597633806725 0.9871404740669323
epoch:3, iteration:30
1.481958031654358 2.4781386852264404 0.8305329084396362
lambda: 1.0434863098399172 0.9767279054138222 0.9797857847462608
epoch:3, iteration:35
1.6910806894302368 2.5994153022766113 0.7426794171333313
lambda: 1.0310032206570843 0.9854000611186049 0.9835967182243103
Epoch Dev:	3
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.6807	0.4617	0.4099
Epoch Test:	3
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.6718	0.4505	0.3849
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/Epoch_3.torchsave
whole iter list [3, 34, 38, 15, 35, 7, 10, 18, 23, 0] max:min 39 0
epoch:4, iteration:0
1.2293568849563599 1.5227916240692139 0.8667260408401489
lambda: 1.031038918272593 0.9986024052107727 0.9703586765166344
epoch:4, iteration:5
1.5365229845046997 2.4206929206848145 0.7284786105155945
lambda: 0.8731071598729128 1.1467977497966344 0.9800950903304526
epoch:4, iteration:10
1.447195053100586 1.9510308504104614 0.7935186624526978
lambda: 0.913768934063192 1.0435790825433244 1.0426519833934838
epoch:4, iteration:15
1.3808648586273193 1.9230575561523438 0.6974736452102661
lambda: 1.0341356028897102 0.9152779368415912 1.0505864602686987
epoch:4, iteration:20
1.132349967956543 1.7843908071517944 0.7079254984855652
lambda: 0.9729921453588554 0.9510689235193819 1.0759389311217629
epoch:4, iteration:25
1.1262080669403076 2.0491209030151367 0.7509275078773499
lambda: 1.009738367384958 1.0278384906842135 0.9624231419308283
epoch:4, iteration:30
1.0063397884368896 1.6971009969711304 0.7219585180282593
lambda: 1.0876671257091193 0.8909719022561448 1.0213609720347356
epoch:4, iteration:35
1.192640781402588 1.630253553390503 0.6905564069747925
lambda: 0.9249623252471391 1.1754624679259544 0.8995752068269064
Epoch Dev:	4
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7124	0.4872	0.4424
Epoch Test:	4
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7104	0.4757	0.4191
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/Epoch_4.torchsave
whole iter list [29, 8, 3, 1, 10, 18, 32, 17, 37, 13] max:min 39 0
epoch:5, iteration:0
1.122766137123108 1.2319620847702026 0.7136620879173279
lambda: 1.1163919566550229 0.8615461778624679 1.0220618654825095
epoch:5, iteration:5
1.0386589765548706 1.8874605894088745 0.713923454284668
lambda: 1.0178767163857882 0.9773525311040729 1.0047707525101388
epoch:5, iteration:10
1.2767020463943481 2.0057735443115234 0.7815712690353394
lambda: 1.0341202201485307 0.9696174901657073 0.9962622896857622
epoch:5, iteration:15
1.2386687994003296 1.8859657049179077 0.627458930015564
lambda: 0.9030584576583998 1.0570335477547885 1.039907994586812
epoch:5, iteration:20
1.2935116291046143 1.8791918754577637 0.7270055413246155
lambda: 1.140586562614086 1.0032354308991642 0.8561780064867498
epoch:5, iteration:25
1.0040167570114136 1.4982022047042847 0.6272512078285217
lambda: 0.9398512578546838 1.036359453191093 1.023789288954223
epoch:5, iteration:30
1.1328179836273193 1.0396009683609009 0.703694224357605
lambda: 1.1289168802789862 0.8546082949211002 1.0164748247999138
epoch:5, iteration:35
1.4966704845428467 2.4033544063568115 0.6480444669723511
lambda: 0.9636444008373982 0.9729261918003301 1.0634294073622714
Epoch Dev:	5
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7335	0.5084	0.4714
Epoch Test:	5
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7239	0.4919	0.4460
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/Epoch_5.torchsave
whole iter list [14, 38, 30, 22, 3, 31, 33, 13, 7, 18] max:min 39 0
epoch:6, iteration:0
1.3755401372909546 1.4529688358306885 0.6237807273864746
lambda: 1.2435312996525572 0.9845448253385976 0.771923875008845
epoch:6, iteration:5
1.2700389623641968 1.6432808637619019 0.5978012084960938
lambda: 0.9413261505444631 0.8890489748032339 1.1696248746523028
epoch:6, iteration:10
1.0547846555709839 1.643015742301941 0.7282309532165527
lambda: 0.9263458200875103 0.9827640499934752 1.0908901299190146
epoch:6, iteration:15
0.8627943992614746 1.4172464609146118 0.6290795207023621
lambda: 0.9038127186737567 1.1070763911244164 0.9891108902018264
epoch:6, iteration:20
1.0933747291564941 1.536623477935791 0.5630297064781189
lambda: 0.9033359391370875 0.9669935333284339 1.129670527534479
epoch:6, iteration:25
0.9242243766784668 0.9251073002815247 0.547126293182373
lambda: 1.0707836697254232 0.8158127103290224 1.1134036199455546
epoch:6, iteration:30
0.827395498752594 1.7988864183425903 0.533151388168335
lambda: 0.9628118597691738 1.0334153460652364 1.0037727941655896
epoch:6, iteration:35
1.0738619565963745 1.3061455488204956 0.5299906730651855
lambda: 0.8725939660862032 1.033949289566079 1.0934567443477177
Epoch Dev:	6
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7405	0.5224	0.4828
Epoch Test:	6
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7203	0.4937	0.4550
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/Epoch_6.torchsave
whole iter list [25, 9, 11, 17, 32, 12, 33, 36, 22, 4] max:min 39 0
epoch:7, iteration:0
1.1441534757614136 1.266545295715332 0.6130641102790833
lambda: 1.1389691044567358 0.9087779316290205 0.9522529639142436
epoch:7, iteration:5
0.9836645126342773 1.0378031730651855 0.5610920786857605
lambda: 1.1453858591590027 0.9144023288708336 0.9402118119701637
epoch:7, iteration:10
0.921556830406189 1.3180099725723267 0.5164625644683838
lambda: 0.9774713743673153 0.9542093697639485 1.0683192558687362
epoch:7, iteration:15
0.9307129979133606 1.5572876930236816 0.5356769561767578
lambda: 0.868556672205559 0.9759557424256162 1.1554875853688247
epoch:7, iteration:20
0.7600724697113037 1.4512171745300293 0.524485170841217
lambda: 1.0076338652145052 0.9339429288238581 1.0584232059616367
epoch:7, iteration:25
0.9960603713989258 1.6588464975357056 0.511633038520813
lambda: 1.0207438388907204 0.9157455761629649 1.0635105849463142
epoch:7, iteration:30
1.0453604459762573 0.4868399500846863 0.4790053367614746
lambda: 1.2079802048962331 0.8341364155672084 0.9578833795365586
epoch:7, iteration:35
0.828900158405304 1.551782488822937 0.5011849403381348
lambda: 0.9526287846607718 0.9743269153615538 1.0730442999776744
Epoch Dev:	7
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7361	0.5321	0.4881
Epoch Test:	7
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7383	0.5117	0.4739
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/Epoch_7.torchsave
whole iter list [33, 26, 9, 21, 7, 39, 29, 4, 10, 32] max:min 39 0
epoch:8, iteration:0
0.8643912672996521 1.678749442100525 0.5922245979309082
lambda: 0.9200010306062276 1.069651223054776 1.0103477463389965
epoch:8, iteration:5
0.6692802309989929 0.7798671126365662 0.49899205565452576
lambda: 0.9714470889064285 1.0821985368391662 0.9463543742544054
epoch:8, iteration:10
0.961369514465332 1.270775318145752 0.49832624197006226
lambda: 0.9815446597257634 0.9756236580746309 1.042831682199606
epoch:8, iteration:15
0.7768228054046631 1.1441477537155151 0.5660585165023804
lambda: 0.9570530608619112 0.8659888457720496 1.1769580933660395
epoch:8, iteration:20
0.5937401652336121 1.5676666498184204 0.48274940252304077
lambda: 1.2763857953317534 0.8178071041747143 0.9058071004935323
epoch:8, iteration:25
0.7390922904014587 1.5038998126983643 0.5671048164367676
lambda: 1.0258700129484608 1.0108690238955154 0.963260963156024
epoch:8, iteration:30
0.8323848247528076 0.5958532094955444 0.44063347578048706
lambda: 0.8486512079415718 0.9858100562855808 1.1655387357728473
epoch:8, iteration:35
0.799102783203125 1.2394179105758667 0.5258911848068237
lambda: 1.0149765796175318 0.991242514968599 0.9937809054138694
Epoch Dev:	8
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7441	0.5488	0.5066
Epoch Test:	8
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7311	0.5162	0.4730
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/Epoch_8.torchsave
whole iter list [27, 28, 2, 4, 39, 22, 3, 6, 23, 37] max:min 39 0
epoch:9, iteration:0
0.9396421313285828 1.4454139471054077 0.5431511402130127
lambda: 1.1857678639940032 0.8712828642299975 0.9429492717759992
epoch:9, iteration:5
1.055178165435791 1.7385563850402832 0.5346484184265137
lambda: 1.0714643923051355 0.8515198068703749 1.0770158008244897
epoch:9, iteration:10
0.6541813611984253 1.065685749053955 0.5067791938781738
lambda: 0.9439686208041933 1.0219852224184651 1.0340461567773414
epoch:9, iteration:15
0.7220526337623596 0.6297191977500916 0.5686187744140625
lambda: 0.959416601207698 0.9565552750711825 1.0840281237211196
epoch:9, iteration:20
0.8013830780982971 1.2886406183242798 0.45091497898101807
lambda: 0.8916316468638689 1.0161807826905058 1.0921875704456254
epoch:9, iteration:25
0.6053892374038696 1.155382752418518 0.48708492517471313
lambda: 1.0101156399897648 0.9719844259645951 1.0178999340456405
epoch:9, iteration:30
0.7785159349441528 1.3608397245407104 0.4914838969707489
lambda: 1.0348922046173217 0.9610551466085788 1.0040526487740997
epoch:9, iteration:35
0.801733672618866 1.4848138093948364 0.45668870210647583
lambda: 0.9620772333484454 0.966616874859853 1.0713058917917015
Epoch Dev:	9
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7485	0.5453	0.5031
Epoch Test:	9
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7401	0.5234	0.4829
whole iter list [8, 19, 12, 6, 24, 26, 17, 33, 7, 0] max:min 39 0
epoch:10, iteration:0
0.8872525095939636 1.2978448867797852 0.42490437626838684
lambda: 0.9859175336806121 0.9994730526924291 1.0146094136269588
epoch:10, iteration:5
0.6753948926925659 1.0348947048187256 0.42473024129867554
lambda: 1.0330135584395563 0.9065392581323425 1.0604471834281008
epoch:10, iteration:10
1.0490418672561646 1.5592055320739746 0.5132012367248535
lambda: 0.8596797379457559 0.9439302366936286 1.1963900253606152
epoch:10, iteration:15
0.7722876667976379 1.3721871376037598 0.45668065547943115
lambda: 1.133048408536896 0.8023576795371808 1.0645939119259231
epoch:10, iteration:20
0.5983344912528992 0.8836678266525269 0.4149351418018341
lambda: 0.792126121533589 1.1511898136126046 1.0566840648538063
epoch:10, iteration:25
0.8548369407653809 0.5870271921157837 0.4665779173374176
lambda: 1.0043841896918422 1.1403514679615048 0.8552643423466534
epoch:10, iteration:30
0.7518119812011719 0.9578743577003479 0.5031051635742188
lambda: 0.9118823204163167 1.0569920618868578 1.0311256176968258
epoch:10, iteration:35
0.7214011549949646 1.075791835784912 0.44100823998451233
lambda: 1.0839367473117683 1.039674228656953 0.8763890240312788
Epoch Dev:	10
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7520	0.5638	0.5172
Epoch Test:	10
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7491	0.5360	0.4901
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/Epoch_10.torchsave
whole iter list [35, 4, 34, 5, 20, 29, 1, 28, 3, 36] max:min 39 0
epoch:11, iteration:0
0.509938657283783 1.0851184129714966 0.4366759657859802
lambda: 1.2702161512152002 0.9431834505327416 0.7866003982520581
epoch:11, iteration:5
0.6239089965820312 0.7830135822296143 0.48072344064712524
lambda: 0.995195167047741 0.9664109832788267 1.038393849673432
epoch:11, iteration:10
0.9126237630844116 1.3298113346099854 0.5871660709381104
lambda: 0.9243471537815202 1.19109596282165 0.8845568833968297
epoch:11, iteration:15
0.6688809394836426 0.7600226998329163 0.44189658761024475
lambda: 1.0344295885410804 0.9668318086403261 0.9987386028185937
epoch:11, iteration:20
0.5083281397819519 0.8737808465957642 0.4064978063106537
lambda: 0.9260511306111661 1.2126000275982387 0.8613488417905953
epoch:11, iteration:25
0.5645266771316528 1.035260796546936 0.44452112913131714
lambda: 0.8388450758545074 1.188732305256587 0.9724226188889055
epoch:11, iteration:30
0.43345117568969727 0.9367314577102661 0.5484766960144043
lambda: 1.0104592267418184 0.866640228131078 1.1229005451271035
epoch:11, iteration:35
0.8217349052429199 0.9909054636955261 0.46027904748916626
lambda: 1.049323456264331 0.9675950196439695 0.9830815240916998
Epoch Dev:	11
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7511	0.5629	0.5172
Epoch Test:	11
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7473	0.5369	0.4982
whole iter list [32, 39, 16, 15, 36, 25, 38, 22, 10, 14] max:min 39 0
epoch:12, iteration:0
0.4323013424873352 0.9881224036216736 0.40468254685401917
lambda: 0.9985750712729314 1.0295783631559445 0.971846565571124
epoch:12, iteration:5
0.679803729057312 1.0001546144485474 0.44510290026664734
lambda: 0.9193008995565659 1.138600389183921 0.9420987112595132
epoch:12, iteration:10
0.5277324318885803 0.9855237603187561 0.47574371099472046
lambda: 1.0017902341547549 0.9563103552491703 1.041899410596075
epoch:12, iteration:15
0.4894135594367981 1.2267863750457764 0.43413984775543213
lambda: 1.038800982840603 1.1054618909188558 0.855737126240541
epoch:12, iteration:20
0.5510092973709106 0.5988500118255615 0.46360260248184204
lambda: 0.9062908363717961 1.2555756550473725 0.8381335085808316
epoch:12, iteration:25
0.5400491952896118 1.100580096244812 0.3963549733161926
lambda: 0.9502547170127021 0.995208440207024 1.0545368427802737
epoch:12, iteration:30
0.4257749617099762 0.9266376495361328 0.4762604534626007
lambda: 1.0337428695506305 1.0203877904553367 0.9458693399940324
epoch:12, iteration:35
0.5580284595489502 1.1342791318893433 0.4456768035888672
lambda: 1.015050582289176 0.9098902749494613 1.0750591427613625
Epoch Dev:	12
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7590	0.5787	0.5339
Epoch Test:	12
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7491	0.5342	0.4901
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/Epoch_12.torchsave
whole iter list [30, 19, 26, 0, 14, 10, 8, 24, 2, 36] max:min 39 0
epoch:13, iteration:0
0.3778653144836426 0.836486279964447 0.452622652053833
lambda: 1.1329672335814027 0.9195665028433907 0.9474662635752068
epoch:13, iteration:5
0.8197670578956604 1.2155693769454956 0.4542277157306671
lambda: 1.3641669415260436 0.8187237763691488 0.8171092821048077
epoch:13, iteration:10
0.7796054482460022 1.140586256980896 0.5418812036514282
lambda: 1.0328081988781868 0.9774953280233161 0.9896964730984967
epoch:13, iteration:15
0.654180109500885 0.5051602125167847 0.4656732380390167
lambda: 1.1085734237194789 0.8036061185409326 1.0878204577395887
epoch:13, iteration:20
0.715218186378479 0.8019174933433533 0.4023313522338867
lambda: 0.9528712516135998 1.046171775816787 1.0009569725696132
epoch:13, iteration:25
0.6605021357536316 0.5930662751197815 0.44300365447998047
lambda: 1.0303849417513729 1.0291531187597172 0.9404619394889101
epoch:13, iteration:30
0.6792199015617371 1.3827611207962036 0.3847595453262329
lambda: 0.9393815275330685 0.9608647831751298 1.0997536892918018
epoch:13, iteration:35
0.6360766291618347 0.6028521656990051 0.4014320373535156
lambda: 1.126264926505706 0.9043818459165451 0.9693532275777487
Epoch Dev:	13
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7529	0.5743	0.5312
Epoch Test:	13
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7536	0.5360	0.4946
whole iter list [19, 3, 34, 10, 16, 35, 37, 1, 25, 6] max:min 39 0
epoch:14, iteration:0
0.3739706873893738 0.747870147228241 0.5062910318374634
lambda: 1.0577730462769699 1.0736313527792638 0.8685956009437659
epoch:14, iteration:5
0.33977338671684265 0.8152822256088257 0.415474534034729
lambda: 0.8896346907208378 0.976943986447028 1.1334213228321346
epoch:14, iteration:10
0.6230301260948181 1.2910983562469482 0.46422451734542847
lambda: 0.9268820139594417 1.0729017726326857 1.0002162134078727
epoch:14, iteration:15
0.5608015060424805 0.5312718749046326 0.3946716785430908
lambda: 0.897366738290401 1.1352178586990447 0.967415403010554
epoch:14, iteration:20
0.5300073027610779 0.47095656394958496 0.4335167407989502
lambda: 0.8597217859750503 0.9350000534437121 1.2052781605812377
epoch:14, iteration:25
0.4286642372608185 0.7742243409156799 0.38832855224609375
lambda: 0.9983717220961534 0.9496757160287567 1.0519525618750896
epoch:14, iteration:30
0.8892449140548706 1.6165521144866943 0.43633905053138733
lambda: 0.9905391935228541 0.8813092628243894 1.1281515436527567
epoch:14, iteration:35
0.5257086157798767 1.0085958242416382 0.4135792553424835
lambda: 0.860991887451268 1.1937500182041771 0.9452580943445548
Epoch Dev:	14
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7599	0.5814	0.5312
Epoch Test:	14
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7653	0.5576	0.5090
whole iter list [24, 32, 4, 9, 26, 19, 7, 13, 14, 2] max:min 39 0
epoch:15, iteration:0
0.5051875710487366 0.5994461178779602 0.40610161423683167
lambda: 0.4661005879356012 2.0089150217325646 0.5249843903318344
epoch:15, iteration:5
0.3867442011833191 0.7677168250083923 0.48464763164520264
lambda: 0.8522394537842313 1.1430338053595162 1.0047267408562521
epoch:15, iteration:10
0.439633309841156 0.7158244252204895 0.43044158816337585
lambda: 0.9162464089852382 0.9722662822410792 1.1114873087736823
epoch:15, iteration:15
0.862059473991394 1.1639710664749146 0.4257097840309143
lambda: 1.1275443705920003 0.8375465438798192 1.0349090855281804
epoch:15, iteration:20
0.9169959425926208 1.6054081916809082 0.4193609356880188
lambda: 1.0948999584658439 1.0674629195349634 0.8376371219991927
epoch:15, iteration:25
0.6399827599525452 1.1813629865646362 0.3516530692577362
lambda: 1.0023643128570718 1.04638858383307 0.9512471033098581
epoch:15, iteration:30
0.5970768332481384 0.86601722240448 0.42973434925079346
lambda: 0.7170470789197798 1.3439670610972094 0.9389858599830107
epoch:15, iteration:35
0.5478197932243347 0.843239426612854 0.3722376227378845
lambda: 0.999656080709864 0.8950200945869695 1.1053238247031663
Epoch Dev:	15
F_span_Dev	F_nuclearity_Dev	F_relation_Dev:
0.7617	0.5928	0.5418
Epoch Test:	15
F_segment_Test:	F_span_Test	F_nuclearity_Test
1.0000	0.7545	0.5450	0.4991
saving to torchsave:  depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/Epoch_15.torchsave
--------------------------------------------------------------------
Training Completed!
Processing...
The best Dev epoch is:  15
The best Dev F1 points for Span Nuclearity Relation are:
 0.7617	0.5928	0.5418
Data path: ./data/pickle-data/depth/to_pt/zh-gcdt-hfl-chinese-roberta-wwm-ext/
Model path: depth_mode/Savings/zh-gcdt-hfl-chinese-roberta-wwm-ext_bs1_seed555/
Epoch EvalOnly Test:	15
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7545	0.5450	0.4991
Epoch EvalOnly Test:	15	docid:	0
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7512	0.4880	0.4354
Epoch EvalOnly Test:	15	docid:	1
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7054	0.5349	0.5078
Epoch EvalOnly Test:	15	docid:	2
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7658	0.5570	0.4684
Epoch EvalOnly Test:	15	docid:	3
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7826	0.5815	0.5163
Epoch EvalOnly Test:	15	docid:	4
 F_segment_Test	F_span_Test	F_nuclearity_Test	F_relation_Test:
1.0000	0.7756	0.5644	0.5413
